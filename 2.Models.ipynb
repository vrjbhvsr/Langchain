{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9242d70f",
   "metadata": {},
   "source": [
    "# ðŸ“˜ Topic: Deep dive into Langchain- Models\n",
    "\n",
    "\n",
    "## ðŸŽ¯ Objective\n",
    "* Understanding models in Langchain\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c036836",
   "metadata": {},
   "source": [
    "## Models ðŸ“\n",
    "\n",
    "Models are nothing but the brain of the agents, that does easy to complex tasks. These models are LLMs, which are powerful to understand and interprete human language and reason like human does. They are capable to:\n",
    "\n",
    "- Write content\n",
    "- Answer question\n",
    "- summarize information\n",
    "- Translate languages\n",
    "\n",
    "ðŸ“Œ These models do not required any task specific training, the way traditional machine learning model required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b968bc27",
   "metadata": {},
   "source": [
    "### Initializing the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83845106",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vraj/Langchain/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "DefaultCredentialsError",
     "evalue": "Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mDefaultCredentialsError\u001b[39m                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m chat_model_OPenAi = init_chat_model(\u001b[33m\"\u001b[39m\u001b[33mopenai:gpt-4.1\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;66;03m# Initialising OpenAI's GPT-4.1 chat model\u001b[39;00m\n\u001b[32m     12\u001b[39m chat_model_Anthropic = init_chat_model(\u001b[33m\"\u001b[39m\u001b[33manthropic:claude-2\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;66;03m# Initialising Anthropic's Claude-2 chat model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m chat_model_gemini = \u001b[43minit_chat_model\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgoogle_genai:gemini-1.5-flash-lite\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Initialising Google's Gemini-2.5-flash-lite chat model\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Note: Make sure to set the environment variables OPENAI_API_KEY and ANTHROPIC_API_KEY with your respective API keys before running the code.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Langchain/.venv/lib/python3.12/site-packages/langchain/chat_models/base.py:284\u001b[39m, in \u001b[36minit_chat_model\u001b[39m\u001b[34m(model, model_provider, configurable_fields, config_prefix, **kwargs)\u001b[39m\n\u001b[32m    276\u001b[39m     warnings.warn(\n\u001b[32m    277\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_prefix\u001b[38;5;132;01m=}\u001b[39;00m\u001b[33m has been set but no fields are configurable. Set \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    278\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`configurable_fields=(...)` to specify the model params that are \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    279\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mconfigurable.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    280\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    281\u001b[39m     )\n\u001b[32m    283\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m configurable_fields:\n\u001b[32m--> \u001b[39m\u001b[32m284\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_init_chat_model_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    286\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model:\n\u001b[32m    290\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m] = model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Langchain/.venv/lib/python3.12/site-packages/langchain/chat_models/base.py:341\u001b[39m, in \u001b[36m_init_chat_model_helper\u001b[39m\u001b[34m(model, model_provider, **kwargs)\u001b[39m\n\u001b[32m    338\u001b[39m     _check_pkg(\u001b[33m\"\u001b[39m\u001b[33mlangchain_google_genai\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    339\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_google_genai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatGoogleGenerativeAI\n\u001b[32m--> \u001b[39m\u001b[32m341\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mChatGoogleGenerativeAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model_provider == \u001b[33m\"\u001b[39m\u001b[33mfireworks\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    343\u001b[39m     _check_pkg(\u001b[33m\"\u001b[39m\u001b[33mlangchain_fireworks\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Langchain/.venv/lib/python3.12/site-packages/langchain_google_genai/chat_models.py:1854\u001b[39m, in \u001b[36mChatGoogleGenerativeAI.__init__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m   1847\u001b[39m         suggestion = (\n\u001b[32m   1848\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m Did you mean: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msuggestions[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m?\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m suggestions \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1849\u001b[39m         )\n\u001b[32m   1850\u001b[39m         logger.warning(\n\u001b[32m   1851\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnexpected argument \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1852\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mprovided to ChatGoogleGenerativeAI.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msuggestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1853\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1854\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Langchain/.venv/lib/python3.12/site-packages/langchain_core/load/serializable.py:113\u001b[39m, in \u001b[36mSerializable.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    112\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419  # Intentional blank docstring\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Langchain/.venv/lib/python3.12/site-packages/langchain_google_genai/chat_models.py:1915\u001b[39m, in \u001b[36mChatGoogleGenerativeAI.validate_environment\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1913\u001b[39m         google_api_key = \u001b[38;5;28mself\u001b[39m.google_api_key\n\u001b[32m   1914\u001b[39m transport: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28mself\u001b[39m.transport\n\u001b[32m-> \u001b[39m\u001b[32m1915\u001b[39m \u001b[38;5;28mself\u001b[39m.client = \u001b[43mgenaix\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuild_generative_service\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgoogle_api_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1919\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1920\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransport\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1921\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1922\u001b[39m \u001b[38;5;28mself\u001b[39m.async_client_running = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1923\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Langchain/.venv/lib/python3.12/site-packages/langchain_google_genai/_genai_extension.py:286\u001b[39m, in \u001b[36mbuild_generative_service\u001b[39m\u001b[34m(credentials, api_key, client_options, client_info, transport)\u001b[39m\n\u001b[32m    272\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbuild_generative_service\u001b[39m(\n\u001b[32m    273\u001b[39m     credentials: Optional[credentials.Credentials] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    274\u001b[39m     api_key: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    277\u001b[39m     transport: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    278\u001b[39m ) -> v1betaGenerativeServiceClient:\n\u001b[32m    279\u001b[39m     config = _prepare_config(\n\u001b[32m    280\u001b[39m         credentials=credentials,\n\u001b[32m    281\u001b[39m         api_key=api_key,\n\u001b[32m   (...)\u001b[39m\u001b[32m    284\u001b[39m         client_info=client_info,\n\u001b[32m    285\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mv1betaGenerativeServiceClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Langchain/.venv/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:698\u001b[39m, in \u001b[36mGenerativeServiceClient.__init__\u001b[39m\u001b[34m(self, credentials, transport, client_options, client_info)\u001b[39m\n\u001b[32m    689\u001b[39m     transport_init: Union[\n\u001b[32m    690\u001b[39m         Type[GenerativeServiceTransport],\n\u001b[32m    691\u001b[39m         Callable[..., GenerativeServiceTransport],\n\u001b[32m   (...)\u001b[39m\u001b[32m    695\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m cast(Callable[..., GenerativeServiceTransport], transport)\n\u001b[32m    696\u001b[39m     )\n\u001b[32m    697\u001b[39m     \u001b[38;5;66;03m# initialize with the provided callable or the passed in class\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m698\u001b[39m     \u001b[38;5;28mself\u001b[39m._transport = \u001b[43mtransport_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    699\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcredentials_file\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcredentials_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhost\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_api_endpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscopes\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscopes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclient_cert_source_for_mtls\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_cert_source\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    704\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    706\u001b[39m \u001b[43m        \u001b[49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    707\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    708\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33masync\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m._transport):\n\u001b[32m    711\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m CLIENT_LOGGING_SUPPORTED \u001b[38;5;129;01mand\u001b[39;00m _LOGGER.isEnabledFor(\n\u001b[32m    712\u001b[39m         std_logging.DEBUG\n\u001b[32m    713\u001b[39m     ):  \u001b[38;5;66;03m# pragma: NO COVER\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Langchain/.venv/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/grpc.py:235\u001b[39m, in \u001b[36mGenerativeServiceGrpcTransport.__init__\u001b[39m\u001b[34m(self, host, credentials, credentials_file, scopes, channel, api_mtls_endpoint, client_cert_source, ssl_channel_credentials, client_cert_source_for_mtls, quota_project_id, client_info, always_use_jwt_access, api_audience)\u001b[39m\n\u001b[32m    230\u001b[39m             \u001b[38;5;28mself\u001b[39m._ssl_channel_credentials = grpc.ssl_channel_credentials(\n\u001b[32m    231\u001b[39m                 certificate_chain=cert, private_key=key\n\u001b[32m    232\u001b[39m             )\n\u001b[32m    234\u001b[39m \u001b[38;5;66;03m# The base transport sets the host, credentials and scopes\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhost\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcredentials_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredentials_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscopes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscopes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[43m    \u001b[49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[43m=\u001b[49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._grpc_channel:\n\u001b[32m    247\u001b[39m     \u001b[38;5;66;03m# initialize with the provided callable or the default channel\u001b[39;00m\n\u001b[32m    248\u001b[39m     channel_init = channel \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).create_channel\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Langchain/.venv/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/base.py:105\u001b[39m, in \u001b[36mGenerativeServiceTransport.__init__\u001b[39m\u001b[34m(self, host, credentials, credentials_file, scopes, quota_project_id, client_info, always_use_jwt_access, api_audience, **kwargs)\u001b[39m\n\u001b[32m    101\u001b[39m     credentials, _ = google.auth.load_credentials_from_file(\n\u001b[32m    102\u001b[39m         credentials_file, **scopes_kwargs, quota_project_id=quota_project_id\n\u001b[32m    103\u001b[39m     )\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m credentials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._ignore_credentials:\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     credentials, _ = \u001b[43mgoogle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mscopes_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquota_project_id\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    108\u001b[39m     \u001b[38;5;66;03m# Don't apply audience if the credentials file passed from user.\u001b[39;00m\n\u001b[32m    109\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(credentials, \u001b[33m\"\u001b[39m\u001b[33mwith_gdch_audience\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Langchain/.venv/lib/python3.12/site-packages/google/auth/_default.py:739\u001b[39m, in \u001b[36mdefault\u001b[39m\u001b[34m(scopes, request, quota_project_id, default_scopes)\u001b[39m\n\u001b[32m    731\u001b[39m             _LOGGER.warning(\n\u001b[32m    732\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mNo project ID could be determined. Consider running \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    733\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m`gcloud config set project` or setting the \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    734\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33menvironment variable\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    735\u001b[39m                 environment_vars.PROJECT,\n\u001b[32m    736\u001b[39m             )\n\u001b[32m    737\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m credentials, effective_project_id\n\u001b[32m--> \u001b[39m\u001b[32m739\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)\n",
      "\u001b[31mDefaultCredentialsError\u001b[39m: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information."
     ]
    }
   ],
   "source": [
    "# To initialise a chat model using langchain, init_chat_model function is used. It takes model name and other parameters as input and returns the chat model object.\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# the next step is to define the API key for the model. Most of the models require API key, which are close-source, to take the benefit of their capabilities\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv() # I have stored my API keys in .env file. so using load_dotenv() to load them into environment variables.\n",
    "\n",
    "chat_model_OPenAi = init_chat_model(\"openai:gpt-4.1\") # Initialising OpenAI's GPT-4.1 chat model\n",
    "chat_model_Anthropic = init_chat_model(\"anthropic:claude-2\") # Initialising Anthropic's Claude-2 chat model\n",
    "chat_model_gemini = init_chat_model(\"google_genai:gemini-1.5-flash-lite\") # Initialising Google's Gemini-2.5-flash-lite chat model\n",
    "# Note: Make sure to set the environment variables OPENAI_API_KEY and ANTHROPIC_API_KEY with your respective API keys before running the code.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93a690c",
   "metadata": {},
   "source": [
    "### ERRORRRRRRRRRRR â€¼ï¸\n",
    "\n",
    "* Well, the above error is pretty obvious as I don't have API key to use google's LLMs and Anthropic key.\n",
    "\n",
    "* The one thing that took my attention is that i only have OpenAI's API key, then why only google-gemini gave and error and not Anthropics's claude. â‰ï¸\n",
    "\n",
    "    >ðŸ”Ž After reseach i found that OeenAI and Anthropic asks or validates the API keys or other credentials at the runtime(when invoked) but Gemini integration in Langchain requires API key during the initialisation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5028a5b2",
   "metadata": {},
   "source": [
    "### Modern way of initalising the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5995c878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# installing the required packages\n",
    "!pip install -U \"langchain[openai]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c75d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is very modern way of initialising the models in Langchain. \n",
    "# Using init_chat_model function we can easily switch between different models by just changing the model name string.\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv() \n",
    "\n",
    "chat_model_OpenAi = init_chat_model(\"openai:gpt-4.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3d78a8",
   "metadata": {},
   "source": [
    "### Classic way(Earlier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b84515e",
   "metadata": {},
   "source": [
    "#### OpenAI model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49dca15",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is very classic way of initialising the models in Langchain.\n",
    "# Earlier we used to import the specific model class and then initialise it by passing the model name and API key as parameters.\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "#Initialising OpenAI's GPT-4o-mini chat model\n",
    "chat_model_OpenAi = ChatOpenAI(model_name=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd594f04",
   "metadata": {},
   "source": [
    "#### Anthropic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa305bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "#Initialising Anthropic's Claude-3.5-sonnet-20241022 chat model\n",
    "chat_model_OpenAi = ChatAnthropic(model_name=\"claude-3-5-sonnet-20241022\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7009510c",
   "metadata": {},
   "source": [
    "#### Google's gemini model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b42411",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected argument 'model_name' provided to ChatGoogleGenerativeAI. Did you mean: 'model'?\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for ChatGoogleGenerativeAI\nmodel\n  Field required [type=missing, input_value={'model_kwargs': {'model_...gemini-1.5-flash-lite'}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/missing",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Load environment variables from .env file\u001b[39;00m\n\u001b[32m      5\u001b[39m load_dotenv()\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m chat_model_OpenAi = \u001b[43mChatGoogleGenerativeAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgemini-1.5-flash-lite\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Langchain/.venv/lib/python3.12/site-packages/langchain_google_genai/chat_models.py:1854\u001b[39m, in \u001b[36mChatGoogleGenerativeAI.__init__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m   1847\u001b[39m         suggestion = (\n\u001b[32m   1848\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m Did you mean: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msuggestions[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m?\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m suggestions \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1849\u001b[39m         )\n\u001b[32m   1850\u001b[39m         logger.warning(\n\u001b[32m   1851\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnexpected argument \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1852\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mprovided to ChatGoogleGenerativeAI.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msuggestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1853\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1854\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Langchain/.venv/lib/python3.12/site-packages/langchain_core/load/serializable.py:113\u001b[39m, in \u001b[36mSerializable.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    112\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419  # Intentional blank docstring\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Langchain/.venv/lib/python3.12/site-packages/pydantic/main.py:250\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    249\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    252\u001b[39m     warnings.warn(\n\u001b[32m    253\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    254\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    255\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    256\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    257\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for ChatGoogleGenerativeAI\nmodel\n  Field required [type=missing, input_value={'model_kwargs': {'model_...gemini-1.5-flash-lite'}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/missing"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "#Initialising Google's gemini-1.5-flash-lite chat model\n",
    "chat_model_OpenAi = ChatGoogleGenerativeAI(model_name=\"gemini-1.5-flash-lite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59132770",
   "metadata": {},
   "source": [
    ">â—ï¸ The above code section is expecting model instead of model_name, varying from the other two models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d391404",
   "metadata": {},
   "outputs": [
    {
     "ename": "DefaultCredentialsError",
     "evalue": "Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mDefaultCredentialsError\u001b[39m                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m load_dotenv()\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m#Initialising Google's gemini-1.5-flash-lite chat model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m chat_model_OpenAi = \u001b[43mChatGoogleGenerativeAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgemini-1.5-flash-lite\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Langchain/.venv/lib/python3.12/site-packages/langchain_google_genai/chat_models.py:1854\u001b[39m, in \u001b[36mChatGoogleGenerativeAI.__init__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m   1847\u001b[39m         suggestion = (\n\u001b[32m   1848\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m Did you mean: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msuggestions[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m?\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m suggestions \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1849\u001b[39m         )\n\u001b[32m   1850\u001b[39m         logger.warning(\n\u001b[32m   1851\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnexpected argument \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1852\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mprovided to ChatGoogleGenerativeAI.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msuggestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1853\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1854\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Langchain/.venv/lib/python3.12/site-packages/langchain_core/load/serializable.py:113\u001b[39m, in \u001b[36mSerializable.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    112\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419  # Intentional blank docstring\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Langchain/.venv/lib/python3.12/site-packages/langchain_google_genai/chat_models.py:1915\u001b[39m, in \u001b[36mChatGoogleGenerativeAI.validate_environment\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1913\u001b[39m         google_api_key = \u001b[38;5;28mself\u001b[39m.google_api_key\n\u001b[32m   1914\u001b[39m transport: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28mself\u001b[39m.transport\n\u001b[32m-> \u001b[39m\u001b[32m1915\u001b[39m \u001b[38;5;28mself\u001b[39m.client = \u001b[43mgenaix\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuild_generative_service\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgoogle_api_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1919\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1920\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransport\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1921\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1922\u001b[39m \u001b[38;5;28mself\u001b[39m.async_client_running = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1923\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Langchain/.venv/lib/python3.12/site-packages/langchain_google_genai/_genai_extension.py:286\u001b[39m, in \u001b[36mbuild_generative_service\u001b[39m\u001b[34m(credentials, api_key, client_options, client_info, transport)\u001b[39m\n\u001b[32m    272\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbuild_generative_service\u001b[39m(\n\u001b[32m    273\u001b[39m     credentials: Optional[credentials.Credentials] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    274\u001b[39m     api_key: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    277\u001b[39m     transport: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    278\u001b[39m ) -> v1betaGenerativeServiceClient:\n\u001b[32m    279\u001b[39m     config = _prepare_config(\n\u001b[32m    280\u001b[39m         credentials=credentials,\n\u001b[32m    281\u001b[39m         api_key=api_key,\n\u001b[32m   (...)\u001b[39m\u001b[32m    284\u001b[39m         client_info=client_info,\n\u001b[32m    285\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mv1betaGenerativeServiceClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Langchain/.venv/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:698\u001b[39m, in \u001b[36mGenerativeServiceClient.__init__\u001b[39m\u001b[34m(self, credentials, transport, client_options, client_info)\u001b[39m\n\u001b[32m    689\u001b[39m     transport_init: Union[\n\u001b[32m    690\u001b[39m         Type[GenerativeServiceTransport],\n\u001b[32m    691\u001b[39m         Callable[..., GenerativeServiceTransport],\n\u001b[32m   (...)\u001b[39m\u001b[32m    695\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m cast(Callable[..., GenerativeServiceTransport], transport)\n\u001b[32m    696\u001b[39m     )\n\u001b[32m    697\u001b[39m     \u001b[38;5;66;03m# initialize with the provided callable or the passed in class\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m698\u001b[39m     \u001b[38;5;28mself\u001b[39m._transport = \u001b[43mtransport_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    699\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcredentials_file\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcredentials_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhost\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_api_endpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscopes\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscopes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclient_cert_source_for_mtls\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_cert_source\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    704\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    706\u001b[39m \u001b[43m        \u001b[49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    707\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    708\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33masync\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m._transport):\n\u001b[32m    711\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m CLIENT_LOGGING_SUPPORTED \u001b[38;5;129;01mand\u001b[39;00m _LOGGER.isEnabledFor(\n\u001b[32m    712\u001b[39m         std_logging.DEBUG\n\u001b[32m    713\u001b[39m     ):  \u001b[38;5;66;03m# pragma: NO COVER\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Langchain/.venv/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/grpc.py:235\u001b[39m, in \u001b[36mGenerativeServiceGrpcTransport.__init__\u001b[39m\u001b[34m(self, host, credentials, credentials_file, scopes, channel, api_mtls_endpoint, client_cert_source, ssl_channel_credentials, client_cert_source_for_mtls, quota_project_id, client_info, always_use_jwt_access, api_audience)\u001b[39m\n\u001b[32m    230\u001b[39m             \u001b[38;5;28mself\u001b[39m._ssl_channel_credentials = grpc.ssl_channel_credentials(\n\u001b[32m    231\u001b[39m                 certificate_chain=cert, private_key=key\n\u001b[32m    232\u001b[39m             )\n\u001b[32m    234\u001b[39m \u001b[38;5;66;03m# The base transport sets the host, credentials and scopes\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhost\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcredentials_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredentials_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscopes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscopes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[43m    \u001b[49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[43m=\u001b[49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._grpc_channel:\n\u001b[32m    247\u001b[39m     \u001b[38;5;66;03m# initialize with the provided callable or the default channel\u001b[39;00m\n\u001b[32m    248\u001b[39m     channel_init = channel \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).create_channel\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Langchain/.venv/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/base.py:105\u001b[39m, in \u001b[36mGenerativeServiceTransport.__init__\u001b[39m\u001b[34m(self, host, credentials, credentials_file, scopes, quota_project_id, client_info, always_use_jwt_access, api_audience, **kwargs)\u001b[39m\n\u001b[32m    101\u001b[39m     credentials, _ = google.auth.load_credentials_from_file(\n\u001b[32m    102\u001b[39m         credentials_file, **scopes_kwargs, quota_project_id=quota_project_id\n\u001b[32m    103\u001b[39m     )\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m credentials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._ignore_credentials:\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     credentials, _ = \u001b[43mgoogle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mscopes_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquota_project_id\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    108\u001b[39m     \u001b[38;5;66;03m# Don't apply audience if the credentials file passed from user.\u001b[39;00m\n\u001b[32m    109\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(credentials, \u001b[33m\"\u001b[39m\u001b[33mwith_gdch_audience\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Langchain/.venv/lib/python3.12/site-packages/google/auth/_default.py:739\u001b[39m, in \u001b[36mdefault\u001b[39m\u001b[34m(scopes, request, quota_project_id, default_scopes)\u001b[39m\n\u001b[32m    731\u001b[39m             _LOGGER.warning(\n\u001b[32m    732\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mNo project ID could be determined. Consider running \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    733\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m`gcloud config set project` or setting the \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    734\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33menvironment variable\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    735\u001b[39m                 environment_vars.PROJECT,\n\u001b[32m    736\u001b[39m             )\n\u001b[32m    737\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m credentials, effective_project_id\n\u001b[32m--> \u001b[39m\u001b[32m739\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)\n",
      "\u001b[31mDefaultCredentialsError\u001b[39m: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information."
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "#Initialising Google's gemini-1.5-flash-lite chat model\n",
    "chat_model_OpenAi = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash-lite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e24de52",
   "metadata": {},
   "source": [
    "## ðŸ”‘ âœï¸Lessons Learned from Initialising Model:\n",
    "\n",
    "âœ… There is two methods,atleast I know this two from `LangchainDocs` and `Youtube`, to intialise the models.\n",
    "\n",
    "âœ… Each LLM provider has different way to process the credentals and other params.\n",
    "\n",
    "âœ… In classical way we need to initialise the model by importing model-specific classes, such as import *`from langchain_openai import ChatOpenAI`*, *`from langchain_google_genai import ChatGoogleGenerativeAI`*.\n",
    "\n",
    "âœ… Model-specific classes may have different keyword arguments, so it's better to use new API `init_chat_model` initialise the model, where we need to specify a string with name of chat model provider and the model we want to use.\n",
    "\n",
    "âœ… We can use `load_dotenv()` to load the envronment variables, without specifying(visibly) in the file. That keeps our seceret keys, credentials safe and secure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a3b91d",
   "metadata": {},
   "source": [
    "## ðŸ“œInvokation Methods to get response from the model\n",
    "\n",
    "* A model only generates output when it invoked.\n",
    "\n",
    "There are three key methods to get the response from the model.\n",
    "1. invoke()\n",
    "2. batch()\n",
    "3. stream()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616e695b",
   "metadata": {},
   "source": [
    "### 1. Invoke() - To get the reponse of a single message or list of messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0167f89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The \"Law of Attraction\" is a philosophy suggesting that positive or negative thoughts bring positive or negative experiences into a person\\'s life. While there isn\\'t a universally agreed-upon set of \"seven laws of attraction,\" various interpretations often highlight key principles associated with the Law of Attraction. Here are seven concepts often discussed in this context:\\n\\n1. **Like Attracts Like**: This principle suggests that similar energies attract each other. Positive thoughts attract positive outcomes, while negative thoughts attract negative experiences.\\n\\n2. **Nature Abhors a Vacuum**: This law posits that removing negative or limiting beliefs and thoughts from your life creates space for new positive experiences and opportunities.\\n\\n3. **The Present is Always Perfect**: Emphasizing the importance of being present, this principle encourages individuals to focus on the current moment rather than dwelling on past mistakes or anxieties about the future.\\n\\n4. **What You Focus On Expands**: The idea here is that when you focus your energy and attention on specific goals or desires, you are more likely to attract those experiences into your life.\\n\\n5. **Visualization**: This involves creating a clear mental image of what you want to attract. Visualization helps clarify your desires and reinforces them in your subconscious mind.\\n\\n6. **Gratitude**: Practicing gratitude allows you to acknowledge and appreciate what you already have, which in turn attracts more positive experiences and abundance into your life.\\n\\n7. **Faith and Belief**: Having strong belief in your desires and the Law of Attraction itself is essential. Trusting that what you want is on its way empowers you and aligns your energy with your goals.\\n\\nThese principles can vary by interpretation, but they collectively embody the essence of the Law of Attraction philosophy.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 346, 'prompt_tokens': 16, 'total_tokens': 362, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CVbUXf9KlCNYGQM95TjfIKCZ7sGgG', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--f07cf415-9842-452d-baa4-b028fb4b7c98-0' usage_metadata={'input_tokens': 16, 'output_tokens': 346, 'total_tokens': 362, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv() \n",
    "\n",
    "#Initialising OpenAI's GPT-4o-mini chat model\n",
    "chat_model_OpenAi = init_chat_model(\"openai:gpt-4o-mini\")\n",
    "\n",
    "response = chat_model_OpenAi.invoke(\"What are the seven laws of attraction?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c545577e",
   "metadata": {},
   "source": [
    "Hmmmmmm.....ðŸ¤”\n",
    "\n",
    "The output has too many details, I am interested in the answer only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15cb1634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The \"Law of Attraction\" is a philosophy suggesting that positive or negative thoughts bring positive or negative experiences into a person's life. While there isn't a universally agreed-upon set of \"seven laws of attraction,\" various interpretations often highlight key principles associated with the Law of Attraction. Here are seven concepts often discussed in this context:\n",
      "\n",
      "1. **Like Attracts Like**: This principle suggests that similar energies attract each other. Positive thoughts attract positive outcomes, while negative thoughts attract negative experiences.\n",
      "\n",
      "2. **Nature Abhors a Vacuum**: This law posits that removing negative or limiting beliefs and thoughts from your life creates space for new positive experiences and opportunities.\n",
      "\n",
      "3. **The Present is Always Perfect**: Emphasizing the importance of being present, this principle encourages individuals to focus on the current moment rather than dwelling on past mistakes or anxieties about the future.\n",
      "\n",
      "4. **What You Focus On Expands**: The idea here is that when you focus your energy and attention on specific goals or desires, you are more likely to attract those experiences into your life.\n",
      "\n",
      "5. **Visualization**: This involves creating a clear mental image of what you want to attract. Visualization helps clarify your desires and reinforces them in your subconscious mind.\n",
      "\n",
      "6. **Gratitude**: Practicing gratitude allows you to acknowledge and appreciate what you already have, which in turn attracts more positive experiences and abundance into your life.\n",
      "\n",
      "7. **Faith and Belief**: Having strong belief in your desires and the Law of Attraction itself is essential. Trusting that what you want is on its way empowers you and aligns your energy with your goals.\n",
      "\n",
      "These principles can vary by interpretation, but they collectively embody the essence of the Law of Attraction philosophy.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0fcf496a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m response_1 = \u001b[43mchat_model_OpenAi\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWho is Narendra Modi?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWho are the worlds three largetst economy?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# This must give error while it is two messages and not a list.\u001b[39;00m\n\u001b[32m      3\u001b[39m ptint(response_1.content)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Langchain/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:374\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    365\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    366\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    367\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    372\u001b[39m     **kwargs: Any,\n\u001b[32m    373\u001b[39m ) -> AIMessage:\n\u001b[32m--> \u001b[39m\u001b[32m374\u001b[39m     config = \u001b[43mensure_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    375\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    376\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    377\u001b[39m         cast(\n\u001b[32m   (...)\u001b[39m\u001b[32m    389\u001b[39m         ).message,\n\u001b[32m    390\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Langchain/.venv/lib/python3.12/site-packages/langchain_core/runnables/config.py:225\u001b[39m, in \u001b[36mensure_config\u001b[39m\u001b[34m(config)\u001b[39m\n\u001b[32m    209\u001b[39m     empty.update(\n\u001b[32m    210\u001b[39m         cast(\n\u001b[32m    211\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mRunnableConfig\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    217\u001b[39m         )\n\u001b[32m    218\u001b[39m     )\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    220\u001b[39m     empty.update(\n\u001b[32m    221\u001b[39m         cast(\n\u001b[32m    222\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mRunnableConfig\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    223\u001b[39m             {\n\u001b[32m    224\u001b[39m                 k: v.copy() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m COPIABLE_KEYS \u001b[38;5;28;01melse\u001b[39;00m v  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m225\u001b[39m                 \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m()\n\u001b[32m    226\u001b[39m                 \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m CONFIG_KEYS\n\u001b[32m    227\u001b[39m             },\n\u001b[32m    228\u001b[39m         )\n\u001b[32m    229\u001b[39m     )\n\u001b[32m    230\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    231\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m config.items():\n",
      "\u001b[31mAttributeError\u001b[39m: 'str' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "response_1 = chat_model_OpenAi.invoke(\"Who is Narendra Modi?\", \"Who are the worlds three largetst economy?\") # This must give error while it is two messages and not a list.\n",
    "\n",
    "ptint(response_1.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b113a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of my last update in October 2023, the world's three largest economies by nominal GDP are:\n",
      "\n",
      "1. **United States**\n",
      "2. **China**\n",
      "3. **Japan**\n",
      "\n",
      "These rankings can change over time due to economic growth rates, exchange rate fluctuations, and other factors, so it's always good to check the latest data for the most current information.\n"
     ]
    }
   ],
   "source": [
    "response_1 = chat_model_OpenAi.invoke([\"Who is Narendra Modi?\", \"Who are the worlds three largetst economy?\"])\n",
    "print(response_1.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979e9ac3",
   "metadata": {},
   "source": [
    "Ehhhhh â“â“â“â“â“â“\n",
    "\n",
    "I thought, if I send this list of two messages will provide reponse for both.\n",
    "\n",
    "I asked chatGPT, The most straightforward way to call a model is to use invoke() with a single message or a list of messages. then why langchain docs says this line?\n",
    "\n",
    "* \"Single messageâ€ âœ… â€” this is literally a string or a single HumanMessage object.\n",
    "\n",
    "* â€œList of messagesâ€ âœ… â€” this is a list representing a conversation, not multiple independent prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9fa19dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Narendra Modi is the Prime Minister of India, having taken office on May 26, 2014. He is a member of the Bharatiya Janata Party (BJP) and the Rashtriya Swayamsevak Sangh (RSS), a Hindu nationalist organization. Before becoming Prime Minister, Modi served as the Chief Minister of the Indian state of Gujarat from 2001 to 2014. His tenure as Prime Minister has been marked by several significant initiatives, including economic reforms, the \"Make in India\" campaign, the Goods and Services Tax (GST) implementation, and efforts to enhance infrastructure and digital connectivity. His government has also faced criticism over issues related to religious tensions and human rights.\n",
      "\n",
      "As for the world's largest economies, as of 2023, they are generally considered to be:\n",
      "\n",
      "1. **United States**: The largest economy in the world, driven by advanced technology, finance, and consumer markets.\n",
      "2. **China**: The second-largest economy, known for its manufacturing capabilities and rapid economic growth over the past few decades.\n",
      "3. **Japan**: The third-largest economy, recognized for its technology, automotive industry, and robust service sector.\n",
      "\n",
      "These rankings can fluctuate due to changes in economic growth, exchange rates, and other factors.\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import HumanMessage, SystemMessage\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"openai:gpt-4o-mini\")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"Who is Narendra Modi?\"),\n",
    "    HumanMessage(content=\"Also, who are the world's three largest economies?\")\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff737d2",
   "metadata": {},
   "source": [
    "Okay ðŸ¤”, so by list of messages we are sending a converstaion to model and that gives reponse with invoke() method. Also, I think it concatenates the first message so model think it as a one single messsage only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4e50c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"J'adore crÃ©er des applications.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 48, 'total_tokens': 54, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CVbwpWeYRN9GNekXTlVkeY9dRTcan', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--5911a224-eb7c-4a4e-98b7-7128c48f230a-0' usage_metadata={'input_tokens': 48, 'output_tokens': 6, 'total_tokens': 54, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "## From Langchain docs\n",
    "\n",
    "from langchain.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"openai:gpt-4o-mini\")\n",
    "conversation = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant that translates English to French.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Translate: I love programming.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"J'adore la programmation.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Translate: I love building applications.\"}\n",
    "]\n",
    "\n",
    "response = model.invoke(conversation)\n",
    "print(response)  # AIMessage(\"J'adore crÃ©er des applications.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2bd1f04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J'adore crÃ©er des applications.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2614a2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Ich liebe es, Anwendungen zu entwickeln.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 48, 'total_tokens': 56, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_51db84afab', 'id': 'chatcmpl-CVbxPrwBl9x8NeVhP8FOtE2u1h2A0', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--9db1cb97-8d8a-4936-a065-c321b2852470-0' usage_metadata={'input_tokens': 48, 'output_tokens': 8, 'total_tokens': 56, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "## From Langchain docs\n",
    "\n",
    "from langchain.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"openai:gpt-4o-mini\")\n",
    "conversation = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant that translates English to German.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Translate: I love programming.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"J'adore la programmation.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Translate: I love building applications.\"}\n",
    "]\n",
    "\n",
    "response = model.invoke(conversation)\n",
    "print(response)  # AIMessage(\"J'adore crÃ©er des applications.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6eb94e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ich liebe es, Anwendungen zu entwickeln.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1c04d1",
   "metadata": {},
   "source": [
    "ðŸ§‘ðŸ¿â€ðŸ”¬ Just for curiosity, i changed the system message to translate into German instead of french and it repoonded in German even if the assistant in the message has given french translation.\n",
    "\n",
    "â™¨ï¸ That was really fun how a system message can change the way how the model should respond. BUt i think this will come later.\n",
    "\n",
    "â® Back to my list of messages and error: This will open ups an explanation for the another method `batch()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a61cbf",
   "metadata": {},
   "source": [
    "### batch() - It reponse to the collection of multiple independent requests to a model Improving model's performance and reducing costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "378140b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'content'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m chat_model_OpenAi = init_chat_model(\u001b[33m\"\u001b[39m\u001b[33mopenai:gpt-4o-mini\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m response = chat_model_OpenAi.batch([\u001b[33m\"\u001b[39m\u001b[33mWho is Narendra Modi?\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mWho are the worlds three largetst economy?\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontent\u001b[49m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'list' object has no attribute 'content'"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv() \n",
    "\n",
    "#Initialising OpenAI's GPT-4o-mini chat model\n",
    "chat_model_OpenAi = init_chat_model(\"openai:gpt-4o-mini\")\n",
    "\n",
    "response = chat_model_OpenAi.batch([\"Who is Narendra Modi?\", \"Who are the worlds three largetst economy?\"])\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41127548",
   "metadata": {},
   "source": [
    "âœ’ï¸ The reponses are also in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc8fff8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Narendra Modi is an Indian politician serving as the Prime Minister of India since May 2014. He is a member of the Bharatiya Janata Party (BJP) and the Rashtriya Swayamsevak Sangh (RSS), a Hindu nationalist organization. Prior to becoming Prime Minister, Modi served as the Chief Minister of Gujarat from 2001 to 2014.\n",
      "\n",
      "As Prime Minister, Modi has implemented various economic and social reforms, including initiatives like \"Make in India,\" \"Digital India,\" and \"Swachh Bharat Abhiyan\" (Clean India Mission). His government has also focused on infrastructure development, enhancing foreign relations, and tackling issues such as corruption and economic growth.\n",
      "\n",
      "Modi's leadership style and policies have drawn both significant support and criticism. His government has been noted for its emphasis on Hindu nationalism, which has sparked varied reactions in a diverse country like India.\n",
      "As of my last update in October 2023, the three largest economies in the world, measured by nominal GDP, are:\n",
      "\n",
      "1. **United States**\n",
      "2. **China**\n",
      "3. **Japan**\n",
      "\n",
      "These rankings can fluctuate based on economic growth rates and other factors, so it's always good to check the latest data for the most current standings.\n"
     ]
    }
   ],
   "source": [
    "for res in response:\n",
    "    print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9c1344",
   "metadata": {},
   "source": [
    "if we want to receive output for each individual input we can use `batch_as_completed()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "842c15cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, AIMessage(content=\"Parrots have colorful feathers for several reasons, primarily related to their survival, communication, and mate selection:\\n\\n1. **Camouflage**: Bright colors and patterns can help parrots blend into their natural habitats, such as the vibrant foliage of tropical rainforests. This camouflage protects them from predators, allowing them to hide effectively among the leaves and flowers.\\n\\n2. **Social Interaction and Communication**: Colorful feathers are an important aspect of social signaling among parrots. These bright colors can convey information about an individual's health, age, and species, helping parrots establish social hierarchies and interact with one another.\\n\\n3. **Mate Attraction**: In many species, vibrant coloration plays a crucial role in attracting mates. Bright, healthy feathers may indicate a strong and fit individual, making them more appealing to potential partners. The condition and brightness of the feathers can signal genetic fitness.\\n\\n4. **Thermoregulation**: Some research suggests that feather color can help with temperature regulation. Darker colors absorb more heat, which can be beneficial in cooler environments, while lighter colors reflect sunlight, helping to keep birds cool.\\n\\n5. **Sexual Dimorphism**: In some parrot species, males may be more brightly colored than females, which helps females choose mates based on their brightness and health.\\n\\nOverall, the colorful plumage of parrots is a result of evolutionary adaptations that enhance their survival, social interactions, and reproductive success.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 288, 'prompt_tokens': 15, 'total_tokens': 303, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CVcHq2SSFUOP6Gzw6YnyrrPRmReRK', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--083b9fdf-1780-49fe-8cc6-6d55e3ffad8a-0', usage_metadata={'input_tokens': 15, 'output_tokens': 288, 'total_tokens': 303, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}))\n",
      "(2, AIMessage(content='Quantum computing is a type of computation that takes advantage of the principles of quantum mechanics to process information in fundamentally different ways compared to classical computing. While classical computers use bits as the smallest unit of information, which can be either a 0 or a 1, quantum computers use quantum bits, or qubits. Qubits can exist in multiple states simultaneously due to two key quantum phenomena: superposition and entanglement.\\n\\n1. **Superposition**: This allows qubits to be in a state of 0, 1, or both 0 and 1 at the same time. This ability enables quantum computers to process a vast amount of information simultaneously, exponentially increasing their computational power compared to classical computers for certain tasks.\\n\\n2. **Entanglement**: This is a phenomenon where qubits become interconnected, meaning the state of one qubit can depend on the state of another, no matter how far apart they are. This property allows for more complex quantum operations and can lead to faster computations for specific types of problems.\\n\\nQuantum computing holds the potential to solve certain problems more efficiently than classical computers. Some areas where quantum computing could have a significant impact include:\\n\\n- **Cryptography**: Quantum computers could break many of the cryptographic systems currently in use, prompting the development of post-quantum cryptography techniques.\\n- **Optimization problems**: Quantum algorithms have the potential to find optimal solutions to complex problems much faster than classical algorithms.\\n- **Simulations of quantum systems**: They can simulate molecular and atomic interactions, which could revolutionize fields such as medicine, materials science, and chemistry.\\n\\nHowever, as of now, quantum computing is still in the experimental stage, with challenges in scalability, error rates, and stability to be overcome before it can be widely implemented for practical applications.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 361, 'prompt_tokens': 12, 'total_tokens': 373, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CVcHqew2LwmW0vJyAjjnkKhqlen8B', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--c8c50817-75fd-4b2a-9825-2ee5a1b8f72e-0', usage_metadata={'input_tokens': 12, 'output_tokens': 361, 'total_tokens': 373, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}))\n",
      "(1, AIMessage(content=\"Airplanes fly based on the principles of aerodynamics, which involve the interaction between the aircraft's wings and the air. Here are the key concepts that explain how airplanes achieve flight:\\n\\n1. **Four Forces of Flight**: An airplane is affected by four main forces:\\n   - **Lift**: The upward force that opposes gravity. Lift is generated primarily by the wings.\\n   - **Weight**: The downward force due to gravity, acting on the airplane's mass.\\n   - **Thrust**: The forward force that propels the airplane through the air, produced by engines (whether jet engines or propellers).\\n   - **Drag**: The resistance force that opposes thrust, caused by air friction and pressure differences.\\n\\n2. **Wing Design and Airfoil Shape**: \\n   - Airplane wings are designed in a specific shape called an airfoil, which has a curved upper surface and a flatter lower surface. \\n   - As air flows over and under the wings, the shape causes a difference in air pressure. The air moves faster over the top surface, resulting in lower pressure above the wing and higher pressure below, creating lift according to Bernoulli's principle.\\n\\n3. **Angle of Attack**: \\n   - The angle between the wing and the oncoming air is known as the angle of attack. Increasing this angle (up to a certain limit) enhances lift. However, if the angle is too steep, the airflow can separate from the wing's upper surface, leading to a stall and loss of lift.\\n\\n4. **Propulsion and Thrust**: \\n   - Thrust is generated by engines. Jet engines work by expelling exhaust gases backward to provide forward motion (according to Newton's third law of motion, for every action, there is an equal and opposite reaction). Propellers produce thrust by pulling or pushing air.\\n\\n5. **Control Surfaces**: \\n   - Airplanes utilize various control surfaces to manage their flight:\\n     - **Ailerons**: Located on the wings, they control roll.\\n     - **Elevators**: Located on the tail, they control pitch.\\n     - **Rudders**: Located on the vertical stabilizer, they control yaw.\\n\\n6. **Stability and Maneuverability**: \\n   - An aircraftâ€™s design balances stability (its ability to return to level flight after a disturbance) and maneuverability (its ability to change direction). Stability is achieved through proper weight distribution and aerodynamic shapes.\\n\\nWhen an airplane takes off, engines generate thrust, which allows the aircraft to accelerate down the runway. As speed increases, wings generate lift. Once lift exceeds weight, the airplane rises into the air. Pilots then control the aircraft's flight path using the control surfaces and adjust thrust as necessary to maintain cruising altitude and speed. \\n\\nWhen landing, the process is reversed: the pilot reduces thrust, and drag increases as the airplane descends and approaches the runway. \\n\\nOverall, successful flight relies on the careful balance and interplay of these forces and the effective use of aerodynamic principles.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 618, 'prompt_tokens': 12, 'total_tokens': 630, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CVcHrc1bp2bD3HjRykOVuuwjAW8Xw', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--cd2d03e2-4f1b-42c2-9fbb-26706425f952-0', usage_metadata={'input_tokens': 12, 'output_tokens': 618, 'total_tokens': 630, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}))\n"
     ]
    }
   ],
   "source": [
    "## From Langchain docs\n",
    "for response in model.batch_as_completed([\n",
    "    \"Why do parrots have colorful feathers?\",\n",
    "    \"How do airplanes fly?\",\n",
    "    \"What is quantum computing?\"\n",
    "]):\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ce579b",
   "metadata": {},
   "source": [
    "### stream()- Method is used to stream the outputs while they are being generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ce2d937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The theory of relativity, developed by Albert Einstein in the early 20th century, consists of two main parts: special relativity and general relativity. Both of these theories fundamentally changed our understanding of space, time, and gravity.\n",
      "\n",
      "### Special Relativity (1905)\n",
      "Special relativity is based on two postulates:\n",
      "\n",
      "1. **The Principle of Relativity**: The laws of physics are the same in all inertial frames of reference (i.e., frames that are not accelerating). This means that whether you're at rest or moving at a constant speed, the same physical laws apply.\n",
      "\n",
      "2. **Constancy of the Speed of Light**: The speed of light in a vacuum is constant (approximately 299,792 kilometers per second) and is the same for all observers, regardless of their relative motion.\n",
      "\n",
      "Key implications of special relativity include:\n",
      "\n",
      "- **Time Dilation**: Time passes at different rates for observers in different inertial frames. A clock moving relative to an observer will tick slower compared to a clock at rest with that observer.\n",
      "  \n",
      "- **Length Contraction**: Objects moving relative to an observer will appear shortened in the direction of their motion when measured by that observer.\n",
      "  \n",
      "- **Mass-Energy Equivalence**: This concept is encapsulated in the famous equation \\(E=mc^2\\), which states that mass can be converted into energy and vice versa. This relationship explains phenomena in nuclear physics and cosmology.\n",
      "\n",
      "### General Relativity (1915)\n",
      "General relativity extends the principles of special relativity to include accelerated frames of reference and introduces a new concept of gravity. The main ideas include:\n",
      "\n",
      "1. **The Equivalence Principle**: The effects of gravity are locally indistinguishable from acceleration. For example, in a closed, accelerating elevator, a person inside cannot tell whether they are experiencing acceleration or gravity.\n",
      "\n",
      "2. **Curvature of Spacetime**: Instead of describing gravity as a force (as in Newtonian physics), general relativity describes gravity as the curvature of spacetime caused by mass. Massive objects like planets and stars warp the fabric of spacetime around them. Smaller objects move along paths in this curved spacetime, which we perceive as the effect of gravity.\n",
      "\n",
      "Key implications of general relativity include:\n",
      "\n",
      "- **Gravitational Time Dilation**: Time runs slower in strong gravitational fields compared to weaker ones. For instance, clocks closer to a massive body (like Earth) tick more slowly compared to those farther away.\n",
      "\n",
      "- **Black Holes**: Regions of spacetime where gravity is so strong that nothing, not even light, can escape from them.\n",
      "\n",
      "- **Cosmology**: General relativity provides the framework for understanding the large-scale structure of the universe, leading to predictions about phenomena such as the expansion of the universe and the behavior of gravitational waves.\n",
      "\n",
      "Together, the theories of relativity have been confirmed through numerous experiments and have profound implications across physics, from the behavior of subatomic particles to the dynamics of galaxies and cosmic events."
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv() \n",
    "\n",
    "#Initialising OpenAI's GPT-4o-mini chat model\n",
    "chat_model_OpenAi = init_chat_model(\"openai:gpt-4o-mini\")\n",
    "\n",
    "for chunk in model.stream(\"Explain the theory of relativity.\"):\n",
    "    print(chunk.content, end='', sep=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c809309",
   "metadata": {},
   "source": [
    "So, the stream method generates live output, word after word. This increases user experience and better for longer outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e689f7",
   "metadata": {},
   "source": [
    "#### âš ï¸Important: Streaming only works if all steps in the program know how to process a stream of chunks. For instance, an application that isnâ€™t streaming-capable would be one that needs to store the entire output in memory before it can be processed.##from LangchainDocs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadcd191",
   "metadata": {},
   "source": [
    "## Open-Source models\n",
    "\n",
    "* We can use open-source models that are free to use and doesn't require API token. This models may require fine-tunning and maybe they are less accurate than the closed source models.\n",
    "\n",
    "* We can access this open-source models from huggingface hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72043d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U \"langchain[hub]\" \"langchain-huggingface\" huggingface_hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c11dfec3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for ChatHuggingFace\nllm\n  Field required [type=missing, input_value={'model_id': 'deepseek-ai/DeepSeek-V3.2-Exp'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/missing",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdotenv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[32m      4\u001b[39m load_dotenv()\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m model = \u001b[43minit_chat_model\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhuggingface:deepseek-ai/DeepSeek-V3.2-Exp\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m response = model.invoke(\u001b[33m\"\u001b[39m\u001b[33mExplain the theory of relativity.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(response.content)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Langchain/.venv/lib/python3.12/site-packages/langchain/chat_models/base.py:284\u001b[39m, in \u001b[36minit_chat_model\u001b[39m\u001b[34m(model, model_provider, configurable_fields, config_prefix, **kwargs)\u001b[39m\n\u001b[32m    276\u001b[39m     warnings.warn(\n\u001b[32m    277\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_prefix\u001b[38;5;132;01m=}\u001b[39;00m\u001b[33m has been set but no fields are configurable. Set \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    278\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`configurable_fields=(...)` to specify the model params that are \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    279\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mconfigurable.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    280\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    281\u001b[39m     )\n\u001b[32m    283\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m configurable_fields:\n\u001b[32m--> \u001b[39m\u001b[32m284\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_init_chat_model_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    286\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model:\n\u001b[32m    290\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m] = model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Langchain/.venv/lib/python3.12/site-packages/langchain/chat_models/base.py:376\u001b[39m, in \u001b[36m_init_chat_model_helper\u001b[39m\u001b[34m(model, model_provider, **kwargs)\u001b[39m\n\u001b[32m    373\u001b[39m     _check_pkg(\u001b[33m\"\u001b[39m\u001b[33mlangchain_huggingface\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    374\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_huggingface\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatHuggingFace\n\u001b[32m--> \u001b[39m\u001b[32m376\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mChatHuggingFace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model_provider == \u001b[33m\"\u001b[39m\u001b[33mgroq\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    378\u001b[39m     _check_pkg(\u001b[33m\"\u001b[39m\u001b[33mlangchain_groq\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Langchain/.venv/lib/python3.12/site-packages/langchain_huggingface/chat_models/huggingface.py:512\u001b[39m, in \u001b[36mChatHuggingFace.__init__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    511\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, **kwargs: Any):\n\u001b[32m--> \u001b[39m\u001b[32m512\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    513\u001b[39m     \u001b[38;5;28mself\u001b[39m._resolve_model_id()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Langchain/.venv/lib/python3.12/site-packages/langchain_core/load/serializable.py:113\u001b[39m, in \u001b[36mSerializable.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    112\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419  # Intentional blank docstring\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Langchain/.venv/lib/python3.12/site-packages/pydantic/main.py:250\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    249\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    252\u001b[39m     warnings.warn(\n\u001b[32m    253\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    254\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    255\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    256\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    257\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for ChatHuggingFace\nllm\n  Field required [type=missing, input_value={'model_id': 'deepseek-ai/DeepSeek-V3.2-Exp'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/missing"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model = init_chat_model(\"huggingface:deepseek-ai/DeepSeek-V3.2-Exp\")\n",
    "\n",
    "response = model.invoke(\"Explain the theory of relativity.\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e11687",
   "metadata": {},
   "source": [
    "#### âŒâŒ So, in the case of using hugging face using `init_chat_model()` gives an error. I believe, using classical way to initialise hugging face will work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8965924c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course. Here is an explanation of the theory of relativity, broken down from a simple overview to its more complex components.\n",
      "\n",
      "### The Core Idea in a Nutshell\n",
      "\n",
      "The theory of relativity is actually two related theories proposed by Albert Einstein:\n",
      "\n",
      "1.  **Special Relativity (1905):** Deals with objects moving at constant, high speeds in a straight line (i.e., without gravity).\n",
      "2.  **General Relativity (1915):** Expands the theory to include gravity and acceleration.\n",
      "\n",
      "The central, mind-bending idea that connects them is that **the laws of physics are the same for all observers, regardless of their relative motion,** and that **space and time are not absolute and separate, but are woven together into a single fabric called \"spacetime.\"**\n",
      "\n",
      "---\n",
      "\n",
      "### Part 1: Special Relativity\n",
      "\n",
      "Special relativity is built on two simple but powerful postulates:\n",
      "\n",
      "1.  **The Principle of Relativity:** The laws of physics are identical in all inertial (non-accelerating) frames of reference.\n",
      "2.  **The Constancy of the Speed of Light:** The speed of light in a vacuum (\\(c\\)) is the same for all observers, regardless of the motion of the light source or the observer.\n",
      "\n",
      "From these two ideas, several revolutionary consequences emerge:\n",
      "\n",
      "#### Key Consequences of Special Relativity\n",
      "\n",
      "**1. Time Dilation: Moving Clocks Run Slow**\n",
      "If you observe a clock moving relative to you, you will see it tick slower than a clock you are holding. This isn't a mechanical defect; **time itself passes more slowly for the moving object.**\n",
      "\n",
      "*   **Famous Example:** The Twin Paradox. One twin stays on Earth while the other travels at near-light speed to a distant star and back. The traveling twin would be younger than the Earth-bound twin upon return.\n",
      "\n",
      "**2. Length Contraction: Objects Shrink in the Direction of Motion**\n",
      "An object moving relative to you will appear shorter in its direction of motion compared to when it is at rest.\n",
      "\n",
      "**3. Relativity of Simultaneity: \"Now\" is not universal.**\n",
      "Two events that appear simultaneous to one observer may not be simultaneous to another observer who is moving relative to the first. There is no single, universal \"present.\"\n",
      "\n",
      "**4. Mass-Energy Equivalence: E=mcÂ²**\n",
      "This is the most famous equation in the world. It states that mass (\\(m\\)) and energy (\\(E\\)) are two forms of the same thing. The speed of light (\\(c\\)) is the conversion factor. A small amount of mass contains a colossal amount of energy, which is the principle behind nuclear power and atomic bombs.\n",
      "\n",
      "---\n",
      "\n",
      "### Part 2: General Relativity\n",
      "\n",
      "Special relativity worked perfectly without gravity. Einstein's next leap was to incorporate it. His key insight was the **Equivalence Principle**.\n",
      "\n",
      "#### The Equivalence Principle\n",
      "The effects of gravity are locally indistinguishable from the effects of acceleration.\n",
      "\n",
      "*   **Thought Experiment:** Imagine you are in a windowless elevator. If you feel your feet pressed firmly against the floor, you could be standing stationary on Earth (feeling gravity) **or** you could be in a rocket accelerating through space at 9.8 m/sÂ². There is no experiment you could do inside the elevator to tell the difference.\n",
      "\n",
      "This led Einstein to a new description of gravity.\n",
      "\n",
      "#### Gravity as the Curvature of Spacetime\n",
      "Instead of thinking of gravity as a mysterious \"force\" acting at a distance (as Newton did), General Relativity posits that:\n",
      "\n",
      "*   **Mass and energy tell spacetime how to curve.**\n",
      "*   **Curved spacetime tells objects how to move.**\n",
      "\n",
      "A common analogy is a rubber sheet. If you place a heavy bowling ball (like the Sun) in the center, it creates a deep dimple. If you then roll a marble (like the Earth) nearby, it will follow a curved path, or \"orbit,\" around the bowling ball. The marble isn't being \"pulled\" by a force; it's simply following the shortest possible path (a **geodesic**) through the curved geometry of the sheet.\n",
      "\n",
      "![Spacetime Curvature Analogy](https://upload.wikimedia.org/wikipedia/commons/thumb/2/22/Spacetime_curvature.png/440px-Spacetime_curvature.png)\n",
      "\n",
      "#### Key Consequences of General Relativity\n",
      "\n",
      "**1. Gravitational Time Dilation:**\n",
      "Time runs slower in a stronger gravitational field. A clock at sea level (where gravity is stronger) will tick slightly slower than a clock on a mountain top. This is crucial for the accuracy of GPS satellites, which must account for this effect.\n",
      "\n",
      "**2. Bending of Light (Gravitational Lensing):**\n",
      "Since light travels in straight lines through spacetime, if spacetime is curved, light's path will appear to bend. This was first confirmed in 1919 when starlight was observed bending around the Sun during a solar eclipse.\n",
      "\n",
      "**3. Gravitational Redshift:**\n",
      "Light climbing out of a strong gravitational field loses energy. Since the energy of light is related to its frequency, the light shifts towards the red end of the spectrum.\n",
      "\n",
      "**4. The Expansion of the Universe and Black Holes:**\n",
      "General Relativity is the foundation of modern cosmology. It predicted that the universe is dynamic (either expanding or contracting), which was later confirmed. It also predicts the existence of **black holes**â€”objects so dense that they create a region of spacetime from which not even light can escape.\n",
      "\n",
      "### Summary Table\n",
      "\n",
      "| Feature | Special Relativity | General Relativity |\n",
      "| :--- | :--- | :--- |\n",
      "| **Scope** | Constant velocity (no acceleration or gravity) | Includes acceleration and gravity |\n",
      "| **Core Idea** | Laws of physics & light speed are constant for all observers. | Gravity is the curvature of spacetime caused by mass and energy. |\n",
      "| **Key Effects** | Time Dilation, Length Contraction, \\(E=mc^2\\) | Gravitational Time Dilation, Light Bending, Black Holes |\n",
      "| **Analogy** | - | A ball on a stretched rubber sheet |\n",
      "\n",
      "In essence, relativity replaced Newton's absolute space and time with a single, flexible entityâ€”spacetimeâ€”whose geometry is dynamically shaped by the matter and energy within it. It is the theory we use to understand the universe at its largest and most massive scales.\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "LLM = HuggingFaceEndpoint(repo_id = \"deepseek-ai/DeepSeek-V3.2-Exp\", task = \"text-generation\")\n",
    "\n",
    "model = ChatHuggingFace(llm=LLM)\n",
    "\n",
    "response = model.invoke(\"Explain the theory of relativity.\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8549d65d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course. Let's break down the Theory of Relativity. It's actually two interconnected theories proposed by Albert Einstein:\n",
      "\n",
      "1.  **Special Relativity (1905)**\n",
      "2.  **General Relativity (1915)**\n",
      "\n",
      "Think of **Special Relativity** as the rules for objects moving at constant, high speeds in a straight line (like starships in empty space), and **General Relativity** as the expanded theory that includes acceleration and explains how gravity works.\n",
      "\n",
      "---\n",
      "\n",
      "### 1. Special Relativity: The Physics of High Speed\n",
      "\n",
      "Before Einstein, everyone thought space and time were absolute and separate. Einstein showed they are relative and intertwined into a single fabric: **spacetime**.\n",
      "\n",
      "Special Relativity rests on two simple but revolutionary postulates:\n",
      "\n",
      "*   **Postulate 1: The Laws of Physics are the same for all observers in uniform motion (i.e., not accelerating).**\n",
      "    *   Whether you're standing still or moving in a car at a constant 60 mph, if you drop a ball, it behaves the same way. There is no single, privileged \"at rest\" frame of reference.\n",
      "\n",
      "*   **Postulate 2: The Speed of Light in a vacuum is constant for all observers.**\n",
      "    *   No matter how fast you are moving when you measure it, light always travels at 299,792,458 meters per second. If you're in a spaceship traveling at 99% the speed of light and you turn on your headlights, the light from your headlights *still* moves away from you at the full speed of light, not 1% faster.\n",
      "\n",
      "From these two simple ideas, mind-bending consequences emerge:\n",
      "\n",
      "#### Key Consequences of Special Relativity:\n",
      "\n",
      "*   **Time Dilation: Moving clocks run slow.**\n",
      "    *   If you are moving relative to someone else, they will see your clock ticking slower than theirs. This isn't a mechanical error; time itself is stretching. An astronaut on a fast-moving spaceship would age slower than their twin on Earth (the famous \"Twin Paradox\").\n",
      "\n",
      "*   **Length Contraction: Moving objects shorten.**\n",
      "    *   An object moving relative to you will appear shorter in its direction of motion. A 100-meter-long spaceship flying past you at high speed would look shorter than 100 meters to you, but perfectly normal to someone on board.\n",
      "\n",
      "*   **Relativity of Simultaneity: Events that are simultaneous for one observer may not be for another.**\n",
      "    *   If two bolts of lightning strike the ends of a moving train at the same time for an observer on the ground, a person on the train might see one bolt strike *before* the other.\n",
      "\n",
      "*   **Mass-Energy Equivalence: E=mcÂ²**\n",
      "    *   This is the most famous equation in the world. It states that energy (E) and mass (m) are two forms of the same thing. The \"cÂ²\" is the speed of light squared, which is a huge number. This means a tiny amount of mass can be converted into a colossal amount of energy (this is the principle behind nuclear power and atomic bombs).\n",
      "\n",
      "---\n",
      "\n",
      "### 2. General Relativity: The Physics of Gravity and Acceleration\n",
      "\n",
      "Einstein realized that Special Relativity didn't account for gravity. He spent a decade expanding his theory to include it.\n",
      "\n",
      "#### The Core Idea: Gravity is not a force, but a curvature of spacetime.\n",
      "\n",
      "Imagine spacetime as a stretched, flexible rubber sheet.\n",
      "\n",
      "*   A massive object, like the Sun, sits in the middle of this sheet, creating a deep dip or curvature.\n",
      "*   The Earth, being less massive, creates a smaller dip.\n",
      "*   The Earth doesn't orbit the Sun because a mysterious \"force\" is pulling it. Instead, it follows a straight-line path (a \"geodesic\") within the curved spacetime created by the Sun. It's like rolling a marble around the rim of a bowlâ€”the marble follows the curve.\n",
      "\n",
      "#### Key Consequences of General Relativity:\n",
      "\n",
      "*   **Gravitational Time Dilation: Gravity slows down time.**\n",
      "    *   The stronger the gravity, the slower time passes. A clock at sea level (where gravity is stronger) ticks slightly slower than a clock on a mountain top. Your GPS has to account for this, or it would be inaccurate by several miles per day!\n",
      "\n",
      "*   **Bending of Light (Gravitational Lensing):**\n",
      "    *   Since light travels through spacetime, its path is bent when it passes near a massive object. This was first confirmed in 1919 when stars near the Sun during a solar eclipse appeared to be in the wrong place because the Sun's gravity bent their light.\n",
      "\n",
      "*   **Gravitational Waves:**\n",
      "    *   When massive objects (like black holes) accelerate and collide, they create ripples in the fabric of spacetime that travel outward at the speed of light. These were directly detected for the first time in 2015 by LIGO.\n",
      "\n",
      "*   **The Expansion of the Universe:**\n",
      "    *   General Relativity's equations originally suggested the universe should be either expanding or contracting, leading to the discovery of the Big Bang.\n",
      "\n",
      "---\n",
      "\n",
      "### Summary: Special vs. General\n",
      "\n",
      "| Feature | Special Relativity | General Relativity |\n",
      "| :--- | :--- | :--- |\n",
      "| **What it Describes** | Objects moving at constant, high speed (no acceleration). | Gravity and acceleration. |\n",
      "| **Core Idea** | Space and time are relative and merge into spacetime. | Mass and energy curve spacetime; gravity is the result of this curvature. |\n",
      "| **Key Equation** | E=mcÂ² | Einstein's Field Equations (incredibly complex). |\n",
      "| **Key Effects** | Time Dilation, Length Contraction, Mass-Energy Equivalence. | Gravitational Time Dilation, Light Bending, Black Holes, Expanding Universe. |\n",
      "\n",
      "In short, the Theory of Relativity completely overturned our classical understanding of space, time, and gravity. It's not just a theoretical curiosity; it's essential for the technology we use every day, like GPS, and forms the foundation of modern cosmology."
     ]
    }
   ],
   "source": [
    "# Let's try using streaming with Hugging Face model\n",
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "from dotenv import load_dotenv  \n",
    "\n",
    "load_dotenv()   \n",
    "\n",
    "LLM = HuggingFaceEndpoint(repo_id = \"deepseek-ai/DeepSeek-V3.2-Exp\", task = \"text-generation\")\n",
    "\n",
    "model = ChatHuggingFace(llm=LLM)\n",
    "\n",
    "for chunk in model.stream(\"Explain the theory of relativity.\"):\n",
    "    print(chunk.content, end='', sep=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c3c1dc",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "\n",
    "#### âœï¸While Initiating model we can define aditional parameters as keywords arguments. This parameter helps to tweek models behaviour."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e6e488",
   "metadata": {},
   "source": [
    "### `model`- that I already learned above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03400183",
   "metadata": {},
   "source": [
    "### `api_key`- This the argument where we have to specify api key of specific provider to use LLM required for authentication. It is actually collected by the model automatically from the environment variables. As i don't have to add api_key parameter manually earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e103e82",
   "metadata": {},
   "source": [
    "### `temperature` - This parameter is used to get the creative response from the model. Lower the value random the message generated, higher the value creative the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c53512e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The theory of relativity, developed by Albert Einstein, consists of two main components: special relativity and general relativity. Special relativity, introduced in 1905, asserts that the laws of physics are the same for all observers in uniform motion and that the speed of light is constant regardless of the observer's motion. This leads to the conclusion that time and space are interconnected in a four-dimensional spacetime continuum, resulting in phenomena such as time dilation and length contraction. General relativity, published in 1915, expands on this by describing gravity not as a force but as the curvature of spacetime caused by mass. Together, these theories revolutionized our understanding of time, space, and gravity, fundamentally altering the framework of modern physics.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model = init_chat_model(model = \"openai:gpt-4o-mini\", temperature=0)\n",
    "\n",
    "response = model.invoke(\"Explain the theory of relativity in 5 sentences.\")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b4f4769b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The theory of relativity, developed by Albert Einstein in the early 20th century, consists of two main components: special relativity and general relativity. Special relativity, introduced in 1905, asserts that the laws of physics are the same for all observers in uniform motion and that the speed of light is constant, leading to phenomena like time dilation and length contraction. General relativity, published in 1915, expands on this by describing gravity not as a force but as the curvature of spacetime caused by mass. This means that massive objects like planets and stars bend the fabric of spacetime, affecting the motion of other objects and light around them. Together, these theories revolutionized our understanding of space, time, and gravity, forming the foundation of modern physics.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model = init_chat_model(model = \"openai:gpt-4o-mini\", temperature=0.8)\n",
    "\n",
    "response = model.invoke(\"Explain the theory of relativity in 5 sentences.\")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857ee629",
   "metadata": {},
   "source": [
    "#### ðŸ”ŽIt seems kind of similar to me not fully but almost similar. Let me try by increasing number even higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "13a9739a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The theory of relativity, developed by Albert Einstein, consists of two fundamental parts: special relativity and general relativity. Special relativity, introduced in 1905, posits that the laws of physics are the same for all observers in uniform motion and that the speed of light in a vacuum is constant, leading to phenomena such as time dilation and length contraction. General relativity, published in 1915, extends these ideas to include gravity, describing it not as a force but as the curvature of spacetime caused by mass. This means that massive objects, like planets and stars, warp the fabric of spacetime, influencing the motion of nearby objects. Together, these principles reshaped our understanding of space, time, and gravity, with significant implications for modern physics and cosmology.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model = init_chat_model(model = \"openai:gpt-4o-mini\", temperature=1.5)\n",
    "\n",
    "response = model.invoke(\"Explain the theory of relativity in 5 sentences.\")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509cef85",
   "metadata": {},
   "source": [
    "#### HUHHH, need to change example ðŸ¤£ðŸ¤£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "83f1e789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In emerald silence, whispers weave a tune,  \n",
      "Where golden suns dance on the silver dune.  \n",
      "Majestic mountains blush with evening's glow,  \n",
      "Cascading rivers in joyous fervor flow,  \n",
      "Nature's canvas, infinite, divineâ€”a wondrous boon.  \n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model = init_chat_model(model = \"openai:gpt-4o-mini\", temperature=1.5)\n",
    "\n",
    "response = model.invoke(\"Write a poem on the beauty of nature in five lines.\")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b6f38f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In whispers soft, the breezes play,  \n",
      "Through emerald leaves where shadows sway,  \n",
      "A symphony of blooms unfolds,  \n",
      "As sunlight drapes the hills in gold,  \n",
      "Nature's canvas, pure and bright, a timeless dance of day and night.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model = init_chat_model(model = \"openai:gpt-4o-mini\", temperature=0.5)\n",
    "\n",
    "response = model.invoke(\"Write a poem on the beauty of nature in five lines.\")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "309defee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In whispered winds, the tall trees sway,  \n",
      "Beneath the sun's warm, golden ray.  \n",
      "A symphony of colors blooms,  \n",
      "In tranquil fields where silence looms,  \n",
      "Nature's grace, a timeless ballet.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model = init_chat_model(model = \"openai:gpt-4o-mini\", temperature=0)\n",
    "\n",
    "response = model.invoke(\"Write a poem on the beauty of nature in five lines.\")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19824b7",
   "metadata": {},
   "source": [
    "#### Now, I can differentiate creativity. But the goal was to understand how temperature parameter works and it's done."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca2f885",
   "metadata": {},
   "source": [
    "### `max_tokens` - This parameter limits the total number of tokens in reposnse. So it sets the limit of how long the output should be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bb0f45bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In whispered winds where blossoms sway,  \n",
      "Morning dew\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model = init_chat_model(model = \"openai:gpt-4o-mini\", temperature=0.8, max_tokens=10)\n",
    "\n",
    "response = model.invoke(\"Write a poem on the beauty of nature in five lines.\")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33744a98",
   "metadata": {},
   "source": [
    "## Embedding Models\n",
    "\n",
    "* Embedding are the vector representation of words or tokens. \n",
    "\n",
    "* Embedding models transform raw text-such as sentence or paragraph into a fixed length of vector of numbers that contains semantic meaning.\n",
    "\n",
    "* We can use these vectors to compare and search text based on meaning rather than exact words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e62db7",
   "metadata": {},
   "source": [
    "#### I will learn this when I start learning about indexing and RAG. Because, the langchain Docs is confusing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
