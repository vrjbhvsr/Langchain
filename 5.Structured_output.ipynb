{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23f79441",
   "metadata": {},
   "source": [
    "# üìò Topic: Deep dive into Langchain- Strucutred Output\n",
    "\n",
    "\n",
    "\n",
    "## üéØ Objective\n",
    "###  Understanding structured Output and Output Parsers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8898e0",
   "metadata": {},
   "source": [
    "### üî∂ What is Structure Output?\n",
    "\n",
    "* Usually, when we get the output in the chat(from LLM) is appearing in term of text, meaning it's not stored in specific format.\n",
    "\n",
    "* Structured Output is the LLM output that is in well-defined data format, such as JSON.\n",
    "\n",
    "* This help, when we send our output to another LLM to perform related task. In agentic AI, The output of an LLM can be input of the another LLM to solve the task, this case is a very good example of why we need output in specific structured format\n",
    "\n",
    "####  Structured output allows agents to return data in a specific, predictable format. Instead of parsing natural language responses, you get structured data in the form of JSON objects, Pydantic models, or dataclasses that your application can directly use. -LangchainDocs\n",
    "\n",
    "### üî∂ Use Cases:\n",
    "\n",
    "1. Data Extraction - When we need to store the output of the LLM into database, such as candidates information from the resume.\n",
    "\n",
    "2. Knowledge graph or Scene Graph creation - to connect nodes to edges in scene graph, structured output helps.\n",
    "\n",
    "3. Multi-Agent communications\n",
    "\n",
    "4. function or tool calling\n",
    "\n",
    "#### üîµ Some LLM providers can respond in structured format, and some cannot.\n",
    "\n",
    "üìå Well, According to LangchainDocs they have specifically focused on create_agent class which include `response_format` parameter. I will understand from the perspective of both standalone LLMs and agents. Basically they both follow the same strategy, we just have to add that strategy to `response_format= strategy` for agents.\n",
    "\n",
    "#### When a schema type is provided directly, LangChain automatically chooses `ProviderStrategy` for models supporting native structured output (e.g. OpenAI, Grok), `ToolStrategy` for all other models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31cc64d",
   "metadata": {},
   "source": [
    "## Provider Strategy\n",
    "\n",
    "### 1. TypeDict- Typed dictionary classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20274c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'John Doe', 'email': 'johndoe.dev@gmail.com', 'phone': '+91 98765 43210', 'linkedin_url': 'linkedin.com/in/johndoe-dev', 'github_url': 'github.com/johndoe-dev', 'skills': ['Python', 'JavaScript', 'Bash', 'C++', 'LangChain', 'FastAPI', 'Streamlit', 'PyTorch', 'TensorFlow', 'Docker', 'GitHub Actions', 'AWS (EC2, S3, Lambda)', 'Jenkins', 'Git', 'VS Code', 'Linux', 'Postman', 'Prompt Engineering', 'API Integration', 'Data Visualization (Matplotlib, Seaborn)']}\n"
     ]
    }
   ],
   "source": [
    "# So, we want our model to extract information of candidates from resume. -YOuTube-CampusX\n",
    "\n",
    "from typing import TypedDict\n",
    "from langchain.chat_models import init_chat_model\n",
    "from dotenv import load_dotenv\n",
    "from langchain.messages import HumanMessage\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class candidate_info(TypedDict):\n",
    "    name: str\n",
    "    email: str\n",
    "    skills: list[str]\n",
    "    github_url: str\n",
    "    linkedin_url: str\n",
    "    phone: str\n",
    "\n",
    "chat_model = init_chat_model(\"openai:gpt-4o-mini\")\n",
    "\n",
    "message = HumanMessage(\"\"\"John Doe\n",
    "Bengaluru, India\n",
    "Email: johndoe.dev@gmail.com\n",
    "Phone: +91 98765 43210\n",
    "LinkedIn: linkedin.com/in/johndoe-dev\n",
    "GitHub: github.com/johndoe-dev\n",
    "\n",
    "Objective:\n",
    "Motivated and detail-oriented developer with a passion for building intelligent systems and automation tools. Seeking opportunities to apply skills in machine learning, AI-driven systems, and DevOps pipelines to real-world problems.\n",
    "\n",
    "Education:\n",
    "M.Tech in Artificial Intelligence & Data Science, National Institute of Technology, Trichy (Aug 2023 ‚Äì May 2025)\n",
    "B.E. in Computer Science & Engineering, Visvesvaraya Technological University (Aug 2019 ‚Äì Jun 2023)\n",
    "\n",
    "Skills:\n",
    "Programming: Python, JavaScript, Bash, C++\n",
    "Frameworks: LangChain, FastAPI, Streamlit, PyTorch, TensorFlow\n",
    "DevOps: Docker, GitHub Actions, AWS (EC2, S3, Lambda), Jenkins\n",
    "Tools: Git, VS Code, Linux, Postman\n",
    "Other: Prompt Engineering, API Integration, Data Visualization (Matplotlib, Seaborn)\n",
    "\n",
    "Projects:\n",
    "\n",
    "CellSense: Multi-Agent System for Cell Growth Analysis\n",
    "\n",
    "Built a LangChain-based multi-agent system analyzing biomaterial properties from multimodal data (text, images, tabular).\n",
    "\n",
    "Agents collaborate to summarize research papers, interpret microscope images, and recommend optimal biomaterials.\n",
    "\n",
    "Technologies: Python, LangChain, OpenAI GPT-4, Streamlit.\n",
    "GitHub: github.com/johndoe-dev/cellsense\n",
    "\n",
    "Personalized Learning Assistant\n",
    "\n",
    "Developed a Streamlit app using LangChain that serves as an interactive mentor for learning AI frameworks.\n",
    "\n",
    "Integrated memory and dynamic prompting to simulate adaptive teaching.\n",
    "\n",
    "Deployed on Streamlit Cloud with OpenAI API and Hugging Face integration.\n",
    "GitHub: github.com/johndoe-dev/langchain-learning-assistant\n",
    "\n",
    "DevOps Automation Pipeline\n",
    "\n",
    "Automated CI/CD workflow for a Flask web app using GitHub Actions and Docker.\n",
    "\n",
    "Deployed on AWS EC2 with versioned updates triggered by Git commits.\n",
    "\n",
    "Implemented monitoring using Prometheus and Grafana.\n",
    "GitHub: github.com/johndoe-dev/devops-pipeline\n",
    "\n",
    "Achievements:\n",
    "\n",
    "AWS Certified Solutions Architect ‚Äî Associate (2025)\n",
    "\n",
    "Published paper on Multi-Agent Collaboration in Scientific Data Interpretation at IEEE ICMLA 2024\n",
    "\n",
    "Won 2nd place in Smart India Hackathon 2023 for AI-driven traffic safety solution\n",
    "\n",
    "Languages:\n",
    "English (Fluent), Hindi (Native)\n",
    "                       \"\"\")\n",
    "# The following line enables structured output only for the LLM providers who can generate structured output in given schema.\n",
    "\n",
    "structure_model = chat_model.with_structured_output(candidate_info) \n",
    "\n",
    "response = structure_model.invoke([message])\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "658f9020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John Doe\n",
      "johndoe.dev@gmail.com\n",
      "+91 98765 43210\n",
      "['Python', 'JavaScript', 'Bash', 'C++', 'LangChain', 'FastAPI', 'Streamlit', 'PyTorch', 'TensorFlow', 'Docker', 'GitHub Actions', 'AWS (EC2, S3, Lambda)', 'Jenkins', 'Git', 'VS Code', 'Linux', 'Postman', 'Prompt Engineering', 'API Integration', 'Data Visualization (Matplotlib, Seaborn)']\n",
      "github.com/johndoe-dev\n",
      "linkedin.com/in/johndoe-dev\n"
     ]
    }
   ],
   "source": [
    "print(response['name'])\n",
    "print(response['email'])\n",
    "print(response['phone'])\n",
    "print(response['skills'])\n",
    "print(response['github_url'])\n",
    "print(response['linkedin_url'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ce271a",
   "metadata": {},
   "source": [
    "#### So, the schema is, here, TypedDict, that is dictionary only which contains keys and their given datatyped value. In other words, if `phone: str` then it will give phone number in string only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e6b136",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vraj/Langchain/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'John Doe', 'email': 'johndoe.dev@gmail.com', 'phone': '+91 98765 43210', 'linkedin_url': 'linkedin.com/in/johndoe-dev', 'github_url': 'github.com/johndoe-dev', 'summary': 'Motivated and detail-oriented developer with a passion for building intelligent systems and automation tools. Seeking opportunities to apply skills in machine learning, AI-driven systems, and DevOps pipelines to real-world problems.', 'skills': ['Python', 'JavaScript', 'Bash', 'C++', 'LangChain', 'FastAPI', 'Streamlit', 'PyTorch', 'TensorFlow', 'Docker', 'GitHub Actions', 'AWS (EC2, S3, Lambda)', 'Jenkins', 'Git', 'VS Code', 'Linux', 'Postman', 'Prompt Engineering', 'API Integration', 'Data Visualization (Matplotlib, Seaborn)']}\n"
     ]
    }
   ],
   "source": [
    "## From YouTube Video:  CampusX -GenAI with Langchain - Structured Outputs\n",
    "\n",
    "# Enhanced version with Annotated and Optional fields.\n",
    "\n",
    "# Annotated class will provide additional context for each field to the LLM, meaning it will work as a prompt, a hint, to LLM to generate things we need.\n",
    "\n",
    "\n",
    "from typing import TypedDict, Annotated, Optional\n",
    "from langchain.chat_models import init_chat_model\n",
    "from dotenv import load_dotenv\n",
    "from langchain.messages import HumanMessage\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class candidate_info(TypedDict):\n",
    "    name: Annotated[str, \"Full name of the candidate\"]\n",
    "    email: Annotated[str, \"Email address of the candidate\"]\n",
    "    skills: Annotated[Optional[list[str]], \"List of technical skills possessed by the candidate\"]\n",
    "    github_url: Annotated[Optional[str], \"GitHub profile URL of the candidate\"]\n",
    "    linkedin_url: Annotated[Optional[str], \"LinkedIn profile URL of the candidate\"]\n",
    "    phone: Annotated[Optional[str], \"Phone number of the candidate\"]\n",
    "    summary: Annotated[str, \"A brief summary of the candidate's profile\"]\n",
    "\n",
    "chat_model = init_chat_model(\"openai:gpt-4o-mini\")\n",
    "\n",
    "message = HumanMessage(\"\"\"John Doe\n",
    "Bengaluru, India\n",
    "Email: johndoe.dev@gmail.com\n",
    "Phone: +91 98765 43210\n",
    "LinkedIn: linkedin.com/in/johndoe-dev\n",
    "GitHub: github.com/johndoe-dev\n",
    "\n",
    "Objective:\n",
    "Motivated and detail-oriented developer with a passion for building intelligent systems and automation tools. Seeking opportunities to apply skills in machine learning, AI-driven systems, and DevOps pipelines to real-world problems.\n",
    "\n",
    "Education:\n",
    "M.Tech in Artificial Intelligence & Data Science, National Institute of Technology, Trichy (Aug 2023 ‚Äì May 2025)\n",
    "B.E. in Computer Science & Engineering, Visvesvaraya Technological University (Aug 2019 ‚Äì Jun 2023)\n",
    "\n",
    "Skills:\n",
    "Programming: Python, JavaScript, Bash, C++\n",
    "Frameworks: LangChain, FastAPI, Streamlit, PyTorch, TensorFlow\n",
    "DevOps: Docker, GitHub Actions, AWS (EC2, S3, Lambda), Jenkins\n",
    "Tools: Git, VS Code, Linux, Postman\n",
    "Other: Prompt Engineering, API Integration, Data Visualization (Matplotlib, Seaborn)\n",
    "\n",
    "Projects:\n",
    "\n",
    "CellSense: Multi-Agent System for Cell Growth Analysis\n",
    "\n",
    "Built a LangChain-based multi-agent system analyzing biomaterial properties from multimodal data (text, images, tabular).\n",
    "\n",
    "Agents collaborate to summarize research papers, interpret microscope images, and recommend optimal biomaterials.\n",
    "\n",
    "Technologies: Python, LangChain, OpenAI GPT-4, Streamlit.\n",
    "GitHub: github.com/johndoe-dev/cellsense\n",
    "\n",
    "Personalized Learning Assistant\n",
    "\n",
    "Developed a Streamlit app using LangChain that serves as an interactive mentor for learning AI frameworks.\n",
    "\n",
    "Integrated memory and dynamic prompting to simulate adaptive teaching.\n",
    "\n",
    "Deployed on Streamlit Cloud with OpenAI API and Hugging Face integration.\n",
    "GitHub: github.com/johndoe-dev/langchain-learning-assistant\n",
    "\n",
    "DevOps Automation Pipeline\n",
    "\n",
    "Automated CI/CD workflow for a Flask web app using GitHub Actions and Docker.\n",
    "\n",
    "Deployed on AWS EC2 with versioned updates triggered by Git commits.\n",
    "\n",
    "Implemented monitoring using Prometheus and Grafana.\n",
    "GitHub: github.com/johndoe-dev/devops-pipeline\n",
    "\n",
    "Achievements:\n",
    "\n",
    "AWS Certified Solutions Architect ‚Äî Associate (2025)\n",
    "\n",
    "Published paper on Multi-Agent Collaboration in Scientific Data Interpretation at IEEE ICMLA 2024\n",
    "\n",
    "Won 2nd place in Smart India Hackathon 2023 for AI-driven traffic safety solution\n",
    "\n",
    "Languages:\n",
    "English (Fluent), Hindi (Native)\n",
    "                       \"\"\")\n",
    "# The following line enables structured output only for the LLM providers who can generate structured output in given schema.\n",
    "\n",
    "structure_model = chat_model.with_structured_output(candidate_info) \n",
    "\n",
    "response = structure_model.invoke([message])\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26a9a0e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Motivated and detail-oriented developer with a passion for building intelligent systems and automation tools. Seeking opportunities to apply skills in machine learning, AI-driven systems, and DevOps pipelines to real-world problems.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['summary']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e41c542",
   "metadata": {},
   "source": [
    "## Dataclass- A decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c46b8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'John Doe', 'email': 'johndoe.dev@gmail.com', 'skills': ['Python', 'JavaScript', 'Bash', 'C++', 'LangChain', 'FastAPI', 'Streamlit', 'PyTorch', 'TensorFlow', 'Docker', 'GitHub Actions', 'AWS (EC2, S3, Lambda)', 'Jenkins', 'Git', 'VS Code', 'Linux', 'Postman', 'Prompt Engineering', 'API Integration', 'Data Visualization (Matplotlib, Seaborn)'], 'github_url': 'github.com/johndoe-dev', 'linkedin_url': 'linkedin.com/in/johndoe-dev', 'phone': '+91 98765 43210'}\n"
     ]
    }
   ],
   "source": [
    "## Dataclass- A decorator Works the same way as TypedDict just simpler to use.\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from langchain.chat_models import init_chat_model\n",
    "from dotenv import load_dotenv\n",
    "from langchain.messages import HumanMessage\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "@dataclass\n",
    "class candidate_info:\n",
    "    name: str\n",
    "    email: str\n",
    "    skills: list[str]\n",
    "    github_url: str\n",
    "    linkedin_url: str\n",
    "    phone: str\n",
    "\n",
    "chat_model = init_chat_model(\"openai:gpt-4o-mini\")\n",
    "\n",
    "message = HumanMessage(\"\"\"John Doe\n",
    "Bengaluru, India\n",
    "Email: johndoe.dev@gmail.com\n",
    "Phone: +91 98765 43210\n",
    "LinkedIn: linkedin.com/in/johndoe-dev\n",
    "GitHub: github.com/johndoe-dev\n",
    "\n",
    "Objective:\n",
    "Motivated and detail-oriented developer with a passion for building intelligent systems and automation tools. Seeking opportunities to apply skills in machine learning, AI-driven systems, and DevOps pipelines to real-world problems.\n",
    "\n",
    "Education:\n",
    "M.Tech in Artificial Intelligence & Data Science, National Institute of Technology, Trichy (Aug 2023 ‚Äì May 2025)\n",
    "B.E. in Computer Science & Engineering, Visvesvaraya Technological University (Aug 2019 ‚Äì Jun 2023)\n",
    "\n",
    "Skills:\n",
    "Programming: Python, JavaScript, Bash, C++\n",
    "Frameworks: LangChain, FastAPI, Streamlit, PyTorch, TensorFlow\n",
    "DevOps: Docker, GitHub Actions, AWS (EC2, S3, Lambda), Jenkins\n",
    "Tools: Git, VS Code, Linux, Postman\n",
    "Other: Prompt Engineering, API Integration, Data Visualization (Matplotlib, Seaborn)\n",
    "\n",
    "Projects:\n",
    "\n",
    "CellSense: Multi-Agent System for Cell Growth Analysis\n",
    "\n",
    "Built a LangChain-based multi-agent system analyzing biomaterial properties from multimodal data (text, images, tabular).\n",
    "\n",
    "Agents collaborate to summarize research papers, interpret microscope images, and recommend optimal biomaterials.\n",
    "\n",
    "Technologies: Python, LangChain, OpenAI GPT-4, Streamlit.\n",
    "GitHub: github.com/johndoe-dev/cellsense\n",
    "\n",
    "Personalized Learning Assistant\n",
    "\n",
    "Developed a Streamlit app using LangChain that serves as an interactive mentor for learning AI frameworks.\n",
    "\n",
    "Integrated memory and dynamic prompting to simulate adaptive teaching.\n",
    "\n",
    "Deployed on Streamlit Cloud with OpenAI API and Hugging Face integration.\n",
    "GitHub: github.com/johndoe-dev/langchain-learning-assistant\n",
    "\n",
    "DevOps Automation Pipeline\n",
    "\n",
    "Automated CI/CD workflow for a Flask web app using GitHub Actions and Docker.\n",
    "\n",
    "Deployed on AWS EC2 with versioned updates triggered by Git commits.\n",
    "\n",
    "Implemented monitoring using Prometheus and Grafana.\n",
    "GitHub: github.com/johndoe-dev/devops-pipeline\n",
    "\n",
    "Achievements:\n",
    "\n",
    "AWS Certified Solutions Architect ‚Äî Associate (2025)\n",
    "\n",
    "Published paper on Multi-Agent Collaboration in Scientific Data Interpretation at IEEE ICMLA 2024\n",
    "\n",
    "Won 2nd place in Smart India Hackathon 2023 for AI-driven traffic safety solution\n",
    "\n",
    "Languages:\n",
    "English (Fluent), Hindi (Native)\n",
    "                       \"\"\")\n",
    "# The following line enables structured output only for the LLM providers who can generate structured output in given schema.\n",
    "\n",
    "structure_model = chat_model.with_structured_output(candidate_info) \n",
    "\n",
    "response = structure_model.invoke([message])\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3adab926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Python', 'JavaScript', 'Bash', 'C++', 'LangChain', 'FastAPI', 'Streamlit', 'PyTorch', 'TensorFlow', 'Docker', 'GitHub Actions', 'AWS (EC2, S3, Lambda)', 'Jenkins', 'Git', 'VS Code', 'Linux', 'Postman', 'Prompt Engineering', 'API Integration', 'Data Visualization (Matplotlib, Seaborn)']\n"
     ]
    }
   ],
   "source": [
    "print(response['skills'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d830aa5",
   "metadata": {},
   "source": [
    "## Pydentic - its data validation and data parsing library for pytohn. It ensures the data you work with is correct, structured, and typesafe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53adf300",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for candidate_info\nage\n  Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='Twenty Five', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.12/v/int_parsing",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      7\u001b[39m     age: \u001b[38;5;28mint\u001b[39m\n\u001b[32m     10\u001b[39m IM = {\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mJohn Doe\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mage\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mTwenty Five\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m df= \u001b[43mcandidate_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mIM\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# This will throw an error if the data in IM is not in correct format.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Langchain/.venv/lib/python3.12/site-packages/pydantic/main.py:250\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    249\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    252\u001b[39m     warnings.warn(\n\u001b[32m    253\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    254\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    255\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    256\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    257\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for candidate_info\nage\n  Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='Twenty Five', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.12/v/int_parsing"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# This Helps if the data is not in the correct type then ut will throw an error.\n",
    "\n",
    "class candidate_info(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "\n",
    "\n",
    "IM = {\"name\": \"John Doe\", \"age\": \"Twenty Five\"}\n",
    "\n",
    "df= candidate_info(**IM)  # This will throw an error if the data in IM is not in correct format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1553cdea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AWS Certified Solutions Architect ‚Äî Associate (2025)', 'Published paper on Multi-Agent Collaboration in Scientific Data Interpretation at IEEE ICMLA 2024', 'Won 2nd place in Smart India Hackathon 2023 for AI-driven traffic safety solution']\n"
     ]
    }
   ],
   "source": [
    "## From YouTube Video:  CampusX -GenAI with Langchain - Structured Outputs\n",
    "# Here, Field subclass works same as Annotated class.\n",
    "import re\n",
    "from typing import Optional\n",
    "from langchain.chat_models import init_chat_model\n",
    "from dotenv import load_dotenv\n",
    "from langchain.messages import HumanMessage\n",
    "from pydantic import BaseModel, Field, EmailStr\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class candidate_info(BaseModel):\n",
    "    name: str = Field(description= \"Full name of the candidate\")\n",
    "    email: EmailStr= Field(description= \"Email address of the candidate\")\n",
    "    skills: Optional[list[str]]= Field(description = \"List of technical skills possessed by the candidate\")\n",
    "    github_url: Optional[str]= Field(description=\"GitHub profile URL of the candidate\")\n",
    "    linkedin_url: Optional[str]= Field(description=\"LinkedIn profile URL\")\n",
    "    summary: str = Field(description= \"A brief summary of the candidate's profile\")\n",
    "    Achievements: Optional[list[str]] = Field(description=\"List of notable achievements of the candidate\")\n",
    "\n",
    "chat_model = init_chat_model(\"openai:gpt-4o-mini\")\n",
    "\n",
    "message = HumanMessage(\"\"\"John Doe\n",
    "Bengaluru, India\n",
    "Email: johndoe.dev@gmail.com\n",
    "Phone: +91 98765 43210\n",
    "LinkedIn: linkedin.com/in/johndoe-dev\n",
    "GitHub: github.com/johndoe-dev\n",
    "\n",
    "Objective:\n",
    "Motivated and detail-oriented developer with a passion for building intelligent systems and automation tools. Seeking opportunities to apply skills in machine learning, AI-driven systems, and DevOps pipelines to real-world problems.\n",
    "\n",
    "Education:\n",
    "M.Tech in Artificial Intelligence & Data Science, National Institute of Technology, Trichy (Aug 2023 ‚Äì May 2025)\n",
    "B.E. in Computer Science & Engineering, Visvesvaraya Technological University (Aug 2019 ‚Äì Jun 2023)\n",
    "\n",
    "Skills:\n",
    "Programming: Python, JavaScript, Bash, C++\n",
    "Frameworks: LangChain, FastAPI, Streamlit, PyTorch, TensorFlow\n",
    "DevOps: Docker, GitHub Actions, AWS (EC2, S3, Lambda), Jenkins\n",
    "Tools: Git, VS Code, Linux, Postman\n",
    "Other: Prompt Engineering, API Integration, Data Visualization (Matplotlib, Seaborn)\n",
    "\n",
    "Achievements:\n",
    "\n",
    "AWS Certified Solutions Architect ‚Äî Associate (2025)\n",
    "\n",
    "Published paper on Multi-Agent Collaboration in Scientific Data Interpretation at IEEE ICMLA 2024\n",
    "\n",
    "Won 2nd place in Smart India Hackathon 2023 for AI-driven traffic safety solution\n",
    "\n",
    "Languages:\n",
    "English (Fluent), Hindi (Native)\n",
    "                       \"\"\")\n",
    "# The following line enables structured output only for the LLM providers who can generate structured output in given schema.\n",
    "\n",
    "structure_model = chat_model.with_structured_output(candidate_info) \n",
    "\n",
    "response = structure_model.invoke([message])\n",
    "\n",
    "print(response.Achievements)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93574d67",
   "metadata": {},
   "source": [
    "## JSON-Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c29a6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'John Doe', 'email': 'johndoe.dev@gmail.com', 'skills': ['Python', 'JavaScript', 'Bash', 'C++', 'LangChain', 'FastAPI', 'Streamlit', 'PyTorch', 'TensorFlow', 'Docker', 'GitHub Actions', 'AWS (EC2, S3, Lambda)', 'Jenkins', 'Git', 'VS Code', 'Linux', 'Postman', 'Prompt Engineering', 'API Integration', 'Data Visualization (Matplotlib, Seaborn)'], 'achievements': ['AWS Certified Solutions Architect ‚Äî Associate (2025)', 'Published paper on Multi-Agent Collaboration in Scientific Data Interpretation at IEEE ICMLA 2024', 'Won 2nd place in Smart India Hackathon 2023 for AI-driven traffic safety solution']}\n"
     ]
    }
   ],
   "source": [
    "## From YouTube Video:  CampusX -GenAI with Langchain - Structured Outputs\n",
    "\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from dotenv import load_dotenv\n",
    "from langchain.messages import HumanMessage\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "json_schema = {\n",
    "    \"title\": \"Candidate_Information\",\n",
    "    \"description\": \"Extract key candidate information from a resume text.\",\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"name\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"Full name of the candidate\"\n",
    "        },\n",
    "        \"email\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"Email address of the candidate\"\n",
    "        },\n",
    "        \"skills\": {\n",
    "            \"type\": [\"array\", \"null\"],\n",
    "            \"items\": {\"type\": \"string\"},\n",
    "            \"description\": \"List of technical skills possessed by the candidate\"\n",
    "        },\n",
    "        \"achievements\": {\n",
    "            \"type\": [\"array\", \"null\"],\n",
    "            \"items\": {\"type\": \"string\"},\n",
    "            \"description\": \"List of notable achievements of the candidate\"\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"name\", \"email\"]\n",
    "}\n",
    "\n",
    "\n",
    "chat_model = init_chat_model(\"openai:gpt-4o-mini\")\n",
    "\n",
    "message = HumanMessage(\"\"\"John Doe\n",
    "Bengaluru, India\n",
    "Email: johndoe.dev@gmail.com\n",
    "Phone: +91 98765 43210\n",
    "LinkedIn: linkedin.com/in/johndoe-dev\n",
    "GitHub: github.com/johndoe-dev\n",
    "\n",
    "Objective:\n",
    "Motivated and detail-oriented developer with a passion for building intelligent systems and automation tools. Seeking opportunities to apply skills in machine learning, AI-driven systems, and DevOps pipelines to real-world problems.\n",
    "\n",
    "Education:\n",
    "M.Tech in Artificial Intelligence & Data Science, National Institute of Technology, Trichy (Aug 2023 ‚Äì May 2025)\n",
    "B.E. in Computer Science & Engineering, Visvesvaraya Technological University (Aug 2019 ‚Äì Jun 2023)\n",
    "\n",
    "Skills:\n",
    "Programming: Python, JavaScript, Bash, C++\n",
    "Frameworks: LangChain, FastAPI, Streamlit, PyTorch, TensorFlow\n",
    "DevOps: Docker, GitHub Actions, AWS (EC2, S3, Lambda), Jenkins\n",
    "Tools: Git, VS Code, Linux, Postman\n",
    "Other: Prompt Engineering, API Integration, Data Visualization (Matplotlib, Seaborn)\n",
    "\n",
    "Achievements:\n",
    "\n",
    "AWS Certified Solutions Architect ‚Äî Associate (2025)\n",
    "\n",
    "Published paper on Multi-Agent Collaboration in Scientific Data Interpretation at IEEE ICMLA 2024\n",
    "\n",
    "Won 2nd place in Smart India Hackathon 2023 for AI-driven traffic safety solution\n",
    "\n",
    "Languages:\n",
    "English (Fluent), Hindi (Native)\n",
    "                       \"\"\")\n",
    "# The following line enables structured output only for the LLM providers who can generate structured output in given schema.\n",
    "\n",
    "structure_model = chat_model.with_structured_output(json_schema) \n",
    "\n",
    "response = structure_model.invoke([message])\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec760d7e",
   "metadata": {},
   "source": [
    "# Output Parsers\n",
    "\n",
    "It help to convert raw LLM reposnses(text data) into structured formats.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bd4c84",
   "metadata": {},
   "source": [
    "### 1. strOutputParser - helps to convert any LLM response into string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8c5902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black holes are regions of space with intense gravity where even light cannot escape. This report explores their formation, types (stellar, supermassive, intermediate), and key discoveries like Hawking radiation and gravitational waves. Hawking radiation suggests black holes emit radiation, while gravitational waves were detected in 2015 from a black hole merger by LIGO. Despite their mystery, ongoing research aims to unravel the secrets of these enigmatic cosmic structures.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "chat_model = init_chat_model(\"openai:gpt-3.5-turbo\")\n",
    "\n",
    "\n",
    "template1 = PromptTemplate(template=\"write a detailed report ion {topic}\", input_variables=['topic'])\n",
    "template2 = PromptTemplate(template = \"Write a 5 line summary on the following text. /n {text}\", input_variables=['text'])\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = template1 | chat_model | template2 | chat_model | parser     # Chaining..\n",
    "response = chain.invoke({'topic' : 'black_hole'})\n",
    "\n",
    "print(response)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1758ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\" Hello! I'd be happy to share some recent updates in the AI world. Please note that this list is not exhaustive, and the AI field evolves rapidly:\\n\\n1. **ChatGPT (December 2022)**: Developed by OpenAI, ChatGPT is a model that interacts in a conversational way. It provides responses to a wide range of prompts with a text-based interface. It has gained significant attention due to its ability to answer questions, write essays, summarize books, and more.\\n\\n2. **Google's Bard (February 2023)**: Google's response to ChatGPT, Bard, is a conversational AI model that aims to provide detailed and high-quality responses to a wide range of questions. It's still in the early stages of development and testing.\\n\\n3. **Stable Diffusion Models (SDMs) (2022)**: SDMs are a class of generative models that have shown promising results in image synthesis and text-to-image generation. They are an alternative to Generative Adversarial Networks (GANs) and have the potential to improve the quality and stability of generated content.\\n\\n4. **Hugging Face's Model Hub (2021)**: Hugging Face launched Model Hub, a platform for sharing and discovering pre-trained AI models. This resource is valuable for developers who want to leverage existing models for their projects without having to train their own.\\n\\n5. **Ethical AI Guidelines**: Various organizations, including the European Union, have been working on developing guidelines for ethical AI. These guidelines aim to ensure that AI systems are transparent, accountable, and respect user privacy and rights.\\n\\n6. **AI in Healthcare**: AI is increasingly being used in healthcare for tasks such as diagnosing diseases, predicting patient outcomes, and personalizing treatment plans. For example, Google's DeepMind Health is collaborating with the National Health Service (NHS) in the UK to develop AI tools for healthcare.\\n\\n7. **AI in Climate Change**: AI is being used to analyze vast amounts of data related to climate change, helping scientists better understand the impacts of climate change and develop strategies to mitigate its effects. For example, IBM's Watson is being used to analyze satellite data to monitor deforestation and track the effects of climate change on ecosystems.\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 520, 'prompt_tokens': 15, 'total_tokens': 535}, 'model_name': 'mistralai/Mistral-7B-Instruct-v0.3', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='lc_run--f43776c2-1719-4c70-9ca0-f5acdf7e06af-0' usage_metadata={'input_tokens': 15, 'output_tokens': 520, 'total_tokens': 535}\n"
     ]
    }
   ],
   "source": [
    "# Understanding using opensource model Mistral-7B that doesn't support structured output\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_huggingface import HuggingFaceEndpoint,ChatHuggingFace\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = HuggingFaceEndpoint(repo_id='mistralai/Mistral-7B-Instruct-v0.3', \n",
    "                          task='text_generation')\n",
    "\n",
    "prompt =  PromptTemplate(template =\"hey!, tell me about recent {topic} Updates.\")\n",
    "\n",
    "model = ChatHuggingFace(llm=llm)\n",
    "\n",
    "chain = prompt | model    # Slowly slowly getting idea about how chain works\n",
    "\n",
    "response = chain.invoke({'topic': \"AI\"})\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b080dd8",
   "metadata": {},
   "source": [
    "#### üë©‚Äçüè´ key points:\n",
    "\n",
    "* I use chains(haven't learned yet) by watching Youtube video, saying output parsers works better with chains. Also, it is giving me soe idea about how chains work.\n",
    "\n",
    "* Here, when we use get repsonse, we get result along with meta info. we specifically write `response.content`\n",
    "\n",
    "* Now, trying with string output parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad2caf6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hello! I'd be happy to share some recent updates in the AI world. Please note that this list is not exhaustive, and the AI field evolves rapidly:\n",
      "\n",
      "1. **ChatGPT (December 2022)**: Developed by OpenAI, ChatGPT is a model that interacts in a conversational way. It provides responses to a wide range of prompts with a text-based interface. It has gained significant attention due to its ability to answer questions, write essays, summarize books, and more.\n",
      "\n",
      "2. **Google's Bard (February 2023)**: Google's response to ChatGPT, Bard, is a conversational AI model that aims to provide detailed and high-quality responses to a wide range of questions. It's still in the early stages of development and testing.\n",
      "\n",
      "3. **Stable Diffusion Models (SDMs) (2022)**: SDMs are a class of generative models that have shown promising results in image synthesis and text-to-image generation. They are an alternative to Generative Adversarial Networks (GANs) and have the potential to improve the quality and stability of generated content.\n",
      "\n",
      "4. **Hugging Face's Model Hub (2021)**: Hugging Face launched Model Hub, a platform for sharing and discovering pre-trained AI models. This resource is valuable for developers who want to leverage existing models for their projects without having to train their own.\n",
      "\n",
      "5. **Ethical AI Guidelines**: Various organizations, including the European Union, have been working on developing guidelines for ethical AI. These guidelines aim to ensure that AI systems are transparent, accountable, and respect user privacy and rights.\n",
      "\n",
      "6. **AI in Healthcare**: AI is increasingly being used in healthcare for tasks such as diagnosing diseases, predicting patient outcomes, and personalizing treatment plans. For example, Google's DeepMind Health is collaborating with the National Health Service (NHS) in the UK to develop AI tools for healthcare.\n",
      "\n",
      "7. **AI in Climate Change**: AI is being used to analyze vast amounts of data related to climate change, helping scientists better understand the impacts of climate change and develop strategies to mitigate its effects. For example, IBM's Watson is being used to analyze satellite data to monitor deforestation and track the effects of climate change on ecosystems.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_huggingface import HuggingFaceEndpoint,ChatHuggingFace\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = HuggingFaceEndpoint(repo_id='mistralai/Mistral-7B-Instruct-v0.3', \n",
    "                          task='text_generation')\n",
    "\n",
    "prompt =  PromptTemplate(template =\"hey!, tell me about recent {topic} Updates.\")\n",
    "\n",
    "model = ChatHuggingFace(llm=llm)\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | parser    # Slowly slowly getting idea about how chain works\n",
    "\n",
    "response = chain.invoke({'topic': \"AI\"})\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77809262",
   "metadata": {},
   "source": [
    "#### üë©‚Äçüè´ key points:\n",
    "\n",
    "* So, we don't need to write `reponse.content` here.\n",
    "\n",
    "* But, that cannot be the only case, when we want to call llm twice and send the first output as a prompt to the llm,  we can use the parser output directly using chains, without breaking the chain to extract textual content from the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0795bc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " In summary, recent advancements in AI include:\n",
      "\n",
      "1. ChatGPT (December 2022) - a conversational AI model developed by OpenAI that interacts with a wide range of prompts.\n",
      "2. Google's Bard (February 2023) - a conversational AI model in development by Google, similar to ChatGPT.\n",
      "3. Stable Diffusion Models (SDMs) (2022) - a class of generative models showing promise in image synthesis and text-to-image generation, serving as an alternative to Generative Adversarial Networks (GANs).\n",
      "4. Hugging Face's Model Hub (2021) - a platform for sharing and discovering pre-trained AI models, beneficial for developers.\n",
      "5. Ethical AI Guidelines - ongoing efforts by organizations like the European Union to ensure AI systems are transparent, accountable, and respect user privacy and rights.\n",
      "6. AI in Healthcare - AI is being utilized for tasks such as disease diagnosis, patient outcome prediction, and personalized treatment plans. Google's DeepMind Health is collaborating with the UK's National Health Service (NHS) to develop AI tools for healthcare.\n",
      "7. AI in Climate Change - AI is being used to analyze climate change data, helping scientists understand its impacts and develop strategies to mitigate effects. IBM's Watson is an example of AI being used to analyze satellite data for monitoring deforestation and tracking climate change effects on ecosystems.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_huggingface import HuggingFaceEndpoint,ChatHuggingFace\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = HuggingFaceEndpoint(repo_id='mistralai/Mistral-7B-Instruct-v0.3', \n",
    "                          task='text_generation')\n",
    "\n",
    "\n",
    "model = ChatHuggingFace(llm=llm)\n",
    "\n",
    "\n",
    "prompt1 =  PromptTemplate(template =\"hey!, tell me about recent {topic} Updates.\", input_variables=['topic'])\n",
    "\n",
    "prompt2 = PromptTemplate(template=\"summarise the {text} with clrity.\", input_variables=[\"text\"])\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = prompt1 | model | parser | prompt2 | model | parser   # Slowly slowly getting idea about how chain works\n",
    "\n",
    "response = chain.invoke({'topic': \"AI\"})\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaaab0e2",
   "metadata": {},
   "source": [
    "### 2. JsonOutputParser -  forces the model to output in json format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ffb32c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give me the name, age and city of a fitional person \n",
      " Return a JSON object.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_huggingface import HuggingFaceEndpoint,ChatHuggingFace\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = HuggingFaceEndpoint(repo_id='mistralai/Mistral-7B-Instruct-v0.3', \n",
    "                          task='text_generation')\n",
    "\n",
    "\n",
    "model = ChatHuggingFace(llm=llm)\n",
    "\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "template = PromptTemplate(template=\"give me the name, age and city of a fitional person \\n {format_instruction}\",\n",
    "                          input_variables=[],\n",
    "                          partial_variables={'format_instruction': parser.get_format_instructions()})\n",
    "\n",
    "\n",
    "prompt = template.format()\n",
    "\n",
    "print(prompt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aef0e9b",
   "metadata": {},
   "source": [
    "#### üë©‚Äçüè´ key points:\n",
    "\n",
    "* When we create prompt, when we add partial variables(that runs before runtime), we tell the model via prompt that we want output in specific format.\n",
    "\n",
    "* In above case, I am using `JsonOutputParser` so, the method `get_format_instruction()` get the information about what format we want our ouput to be in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ee52302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' {\\n  \"name\": \"Alexander Blackwood\",\\n  \"age\": 35,\\n  \"city\": \"New York City\"\\n}\\n\\nPlease note that this is a fictional character and the information provided is for the purpose of this response only.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_huggingface import HuggingFaceEndpoint,ChatHuggingFace\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = HuggingFaceEndpoint(repo_id='mistralai/Mistral-7B-Instruct-v0.3', \n",
    "                          task='text_generation')\n",
    "\n",
    "\n",
    "model = ChatHuggingFace(llm=llm)\n",
    "\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "template = PromptTemplate(template=\"give me the name, age and city of a fitional person \\n {format_instruction}\",\n",
    "                          input_variables=[],\n",
    "                          partial_variables={'format_instruction': parser.get_format_instructions()})\n",
    "\n",
    "\n",
    "prompt = template.format() # There is nothing to specify as it there is static prompt.\n",
    "\n",
    "response = model.invoke(prompt)\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f149d14c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Alexander Blackwood', 'age': 35, 'city': 'New York City'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_huggingface import HuggingFaceEndpoint,ChatHuggingFace\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = HuggingFaceEndpoint(repo_id='mistralai/Mistral-7B-Instruct-v0.3', \n",
    "                          task='text_generation')\n",
    "\n",
    "\n",
    "model = ChatHuggingFace(llm=llm)\n",
    "\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "template = PromptTemplate(template=\"give me the name, age and city of a fitional person \\n {format_instruction}\",\n",
    "                          input_variables=[],\n",
    "                          partial_variables={'format_instruction': parser.get_format_instructions()})\n",
    "\n",
    "\n",
    "prompt = template.format() # There is nothing to specify as it there is static prompt.\n",
    "\n",
    "response = model.invoke(prompt)\n",
    "\n",
    "parsed = parser.parse(response.content)\n",
    "\n",
    "parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bc9fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Alexander Blackwood', 'age': 35, 'city': 'New York City'}\n"
     ]
    }
   ],
   "source": [
    "# we can write using chain also\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_huggingface import HuggingFaceEndpoint,ChatHuggingFace\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = HuggingFaceEndpoint(repo_id='mistralai/Mistral-7B-Instruct-v0.3', \n",
    "                          task='text_generation')\n",
    "\n",
    "\n",
    "model = ChatHuggingFace(llm=llm)\n",
    "\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "template = PromptTemplate(template=\"give me the name, age and city of a fitional person \\n {format_instruction}\",\n",
    "                          input_variables=[],\n",
    "                          partial_variables={'format_instruction': parser.get_format_instructions()})\n",
    "\n",
    "\n",
    "prompt = template.format() # There is nothing to specify as it there is static prompt.\n",
    "\n",
    "chain = template | model | parser\n",
    "response = chain.invoke({})\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9653e20b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
