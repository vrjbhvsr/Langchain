{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8e5007d",
   "metadata": {},
   "source": [
    "# üìò Topic: Deep dive into Langchain- langchain_core.ChatPromptTemplate\n",
    "\n",
    "\n",
    "## üéØ Objective\n",
    "###  Understanding static vs dynamic prompt. Understanding ChatPromptTemplate class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af909aa",
   "metadata": {},
   "source": [
    "#### In previous section, 3.Syetm_prompts_and_Messages.ipynb, whichever prompts that I entered was the example of static prompts. \n",
    "\n",
    "#### üîπ Limitation of Fixed Prompts\n",
    "\n",
    "System prompts defined at the beginning of a session remain constant throughout the interaction. This restricts the model‚Äôs ability to adapt to new personality, tasks, tones, or contextual changes.\n",
    "\n",
    "For example, if we set the system prompt as ‚ÄúYou are a Creative Idea Generator,‚Äù the model will continue responding from that perspective across all queries. Consequently, if we later require analytical or mathematically detailed answers instead of purely theoretical or creative ones, we would need to manually modify the system prompt each time‚Äîan impractical approach for dynamic applications.\n",
    "\n",
    "##### üîπ Need for Dynamic Prompting\n",
    "\n",
    "To overcome this limitation, dynamic prompting is introduced. It allows selective modification of certain parts of the prompt based on the current context, user intent, or task type, while keeping the core instruction stable. This enables the model to generate responses that are more relevant, adaptive, and task-specific without requiring constant manual prompt adjustments.Those prompt are defined in very beginning, thst sre fixed. So, it limits the model to adapt with new topic, task, tone and related content.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "601661bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='You are a helpful assistant that translates English to French. Your name is TranslatorBot.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Translate the following English text to French: Hello, how are you?', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "## From YouTube Video: Generative AI using Langchain - CampusX and Langchain Reference\n",
    "\n",
    "# we can make create our messages list using langchain_core module with ChatPromptTemplate class. \n",
    "# This class helps us to create chat prompts with multiple messages like system message, human message, AI message etc.\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "template = ChatPromptTemplate([\n",
    "    (\"system\",\"You are a helpful assistant that translates English to French. Your name is {name}.\"),\n",
    "    (\"human\",\"Translate the following English text to French: {text}\"),\n",
    "])\n",
    "\n",
    "prompt = template.invoke({\"name\": \"TranslatorBot\",\n",
    "                       \"text\": \"Hello, how are you?\"})\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f31da5d",
   "metadata": {},
   "source": [
    "#### üîπ Dynamic Prompt\n",
    "\n",
    "ChatPromptTemplate is a structured way to build the messages that we send to chat model. We can put placeholders that we can change at the time of model calling.-- Dynamic prompting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40809e66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
